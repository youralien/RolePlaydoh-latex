@misc{markel_opferman_landay_piech_2023,
 title={GPTeach: Interactive TA Training with GPT-based Students},
 url={osf.io/preprints/edarxiv/r23bu},
 DOI={10.1145/3573051.3593393},
 publisher={EdArXiv},
 author={Markel, Julia M and Opferman, Steven G and Landay, James A and Piech, Chris},
 year={2023},
 month={Feb}
}
@misc{chen2023llmempowered,
  title={LLM-empowered Chatbots for Psychiatrist and Patient Simulation: Application and Evaluation}, 
  author={Siyuan Chen and Mengyue Wu and Kenny Q. Zhu and Kunyao Lan and Zhiling Zhang and Lyuchun Cui},
  year={2023},
  eprint={2305.13614},
  archivePrefix={arXiv},
  primaryClass={cs.CL}
}
@misc{tu2024conversational,
      title={Towards Conversational Diagnostic AI}, 
      author={Tao Tu and Anil Palepu and Mike Schaekermann and Khaled Saab and Jan Freyberg and Ryutaro Tanno and Amy Wang and Brenna Li and Mohamed Amin and Nenad Tomasev and Shekoofeh Azizi and Karan Singhal and Yong Cheng and Le Hou and Albert Webson and Kavita Kulkarni and S Sara Mahdavi and Christopher Semturs and Juraj Gottweis and Joelle Barral and Katherine Chou and Greg S Corrado and Yossi Matias and Alan Karthikesalingam and Vivek Natarajan},
      year={2024},
      eprint={2401.05654},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}
@article{othlinghaus2020seriousroleplaying,
  
    AUTHOR={Othlinghaus-Wulhorst, Julia and Hoppe, H. Ulrich},   
    	 
    TITLE={A Technical and Conceptual Framework for Serious Role-Playing Games in the Area of Social Skill Training},      
    	
    JOURNAL={Frontiers in Computer Science},      
    	
    VOLUME={2},           
    	
    YEAR={2020},      
    	  
    URL={https://www.frontiersin.org/articles/10.3389/fcomp.2020.00028},
    DOI={10.3389/fcomp.2020.00028},
    ISSN={2624-9898},   
}
@inproceedings{park2022social,
  title={Social simulacra: Creating populated prototypes for social computing systems},
  author={Park, Joon Sung and Popowski, Lindsay and Cai, Carrie and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
  booktitle={Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology},
  pages={1--18},
  year={2022}
}
@misc{liang2023let,
      title={Let GPT be a Math Tutor: Teaching Math Word Problem Solvers with Customized Exercise Generation}, 
      author={Zhenwen Liang and Wenhao Yu and Tanmay Rajpurohit and Peter Clark and Xiangliang Zhang and Ashwin Kaylan},
      year={2023},
      eprint={2305.14386},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{shaikh2023rehearsal,
      title={Rehearsal: Simulating Conflict to Teach Conflict Resolution}, 
      author={Omar Shaikh and Valentino Chai and Michele J. Gelfand and Diyi Yang and Michael S. Bernstein},
      year={2023},
      eprint={2309.12309},
      archivePrefix={arXiv},
      primaryClass={cs.HC}
}

@article{demszky2023using,
  title={Using large language models in psychology},
  author={Demszky, Dorottya and Yang, Diyi and Yeager, David S and Bryan, Christopher J and Clapper, Margarett and Chandhok, Susannah and Eichstaedt, Johannes C and Hecht, Cameron and Jamieson, Jeremy and Johnson, Meghann and others},
  journal={Nature Reviews Psychology},
  volume={2},
  number={11},
  pages={688--701},
  year={2023},
  publisher={Nature Publishing Group US New York}
}
@article{alinier2022simulation,
  title={Simulation-based education: deceiving learners with good intent},
  author={Alinier, Guillaume and Oriot, Denis},
  journal={Advances in Simulation},
  volume={7},
  number={1},
  pages={8},
  year={2022},
  publisher={Springer}
}

@misc{shi2022life,
      title={When Life Gives You Lemons, Make Cherryade: Converting Feedback from Bad Responses into Good Labels}, 
      author={Weiyan Shi and Emily Dinan and Kurt Shuster and Jason Weston and Jing Xu},
      year={2022},
      eprint={2210.15893},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@inproceedings{cheng-etal-2023-compost,
    title = "{C}o{MP}os{T}: Characterizing and Evaluating Caricature in {LLM} Simulations",
    author = "Cheng, Myra  and
      Piccardi, Tiziano  and
      Yang, Diyi",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.669",
    doi = "10.18653/v1/2023.emnlp-main.669",
    pages = "10853--10875",
}
@misc{gupta2024bias,
      title={Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned LLMs}, 
      author={Shashank Gupta and Vaishnavi Shrivastava and Ameet Deshpande and Ashwin Kalyan and Peter Clark and Ashish Sabharwal and Tushar Khot},
      year={2024},
      eprint={2311.04892},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{christiano2017deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@article{rafailov2024direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@inproceedings{whyjohnnycantprompt,
    author = {Zamfirescu-Pereira, J.D. and Wong, Richmond Y. and Hartmann, Bjoern and Yang, Qian},
    title = {Why Johnny Can’t Prompt: How Non-AI Experts Try (and Fail) to Design LLM Prompts},
    year = {2023},
    isbn = {9781450394215},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3544548.3581388},
    doi = {10.1145/3544548.3581388},
    articleno = {437},
    numpages = {21},
    keywords = {design tools, end-users, language models},
    location = {<conf-loc>, <city>Hamburg</city>, <country>Germany</country>, </conf-loc>},
    series = {CHI '23}
}
@misc{petridis2023constitutionmaker,
      title={ConstitutionMaker: Interactively Critiquing Large Language Models by Converting Feedback into Principles}, 
      author={Savvas Petridis and Ben Wedin and James Wexler and Aaron Donsbach and Mahima Pushkarna and Nitesh Goyal and Carrie J. Cai and Michael Terry},
      year={2023},
      eprint={2310.15428},
      archivePrefix={arXiv},
      primaryClass={cs.HC}
}
@misc{bai2022constitutional,
      title={Constitutional AI: Harmlessness from AI Feedback}, 
      author={Yuntao Bai and Saurav Kadavath and Sandipan Kundu and Amanda Askell and Jackson Kernion and Andy Jones and Anna Chen and Anna Goldie and Azalia Mirhoseini and Cameron McKinnon and Carol Chen and Catherine Olsson and Christopher Olah and Danny Hernandez and Dawn Drain and Deep Ganguli and Dustin Li and Eli Tran-Johnson and Ethan Perez and Jamie Kerr and Jared Mueller and Jeffrey Ladish and Joshua Landau and Kamal Ndousse and Kamile Lukosuite and Liane Lovitt and Michael Sellitto and Nelson Elhage and Nicholas Schiefer and Noemi Mercado and Nova DasSarma and Robert Lasenby and Robin Larson and Sam Ringer and Scott Johnston and Shauna Kravec and Sheer El Showk and Stanislav Fort and Tamera Lanham and Timothy Telleen-Lawton and Tom Conerly and Tom Henighan and Tristan Hume and Samuel R. Bowman and Zac Hatfield-Dodds and Ben Mann and Dario Amodei and Nicholas Joseph and Sam McCandlish and Tom Brown and Jared Kaplan},
      year={2022},
      eprint={2212.08073},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{tanana2019development,
  title={Development and evaluation of ClientBot: Patient-like conversational agent to train basic counseling skills},
  author={Tanana, Michael J and Soma, Christina S and Srikumar, Vivek and Atkins, David C and Imel, Zac E},
  journal={Journal of medical Internet research},
  volume={21},
  number={7},
  pages={e12529},
  year={2019},
  publisher={JMIR Publications Toronto, Canada}
}
@misc{park2023generative,
      title={Generative Agents: Interactive Simulacra of Human Behavior}, 
      author={Joon Sung Park and Joseph C. O'Brien and Carrie J. Cai and Meredith Ringel Morris and Percy Liang and Michael S. Bernstein},
      year={2023},
      eprint={2304.03442},
      archivePrefix={arXiv},
      primaryClass={cs.HC}
}
@misc{zhou2023sotopia,
      title={SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents}, 
      author={Xuhui Zhou and Hao Zhu and Leena Mathur and Ruohong Zhang and Haofei Yu and Zhengyang Qi and Louis-Philippe Morency and Yonatan Bisk and Daniel Fried and Graham Neubig and Maarten Sap},
      year={2023},
      eprint={2310.11667},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}
@misc{zhou2024real,
      title={Is this the real life? Is this just fantasy? The Misleading Success of Simulating Social Interactions With LLMs}, 
      author={Xuhui Zhou and Zhe Su and Tiwalayo Eisape and Hyunwoo Kim and Maarten Sap},
      year={2024},
      eprint={2403.05020},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{jandaghi2023faithful,
      title={Faithful Persona-based Conversational Dataset Generation with Large Language Models}, 
      author={Pegah Jandaghi and XiangHai Sheng and Xinyi Bai and Jay Pujara and Hakim Sidahmed},
      year={2023},
      eprint={2312.10007},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{saha2023branchsolvemerge,
      title={Branch-Solve-Merge Improves Large Language Model Evaluation and Generation}, 
      author={Swarnadeep Saha and Omer Levy and Asli Celikyilmaz and Mohit Bansal and Jason Weston and Xian Li},
      year={2023},
      eprint={2310.15123},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{graphofthought,
   title={Graph of Thoughts: Solving Elaborate Problems with Large Language Models},
   volume={38},
   ISSN={2159-5399},
   url={http://dx.doi.org/10.1609/aaai.v38i16.29720},
   DOI={10.1609/aaai.v38i16.29720},
   number={16},
   journal={Proceedings of the AAAI Conference on Artificial Intelligence},
   publisher={Association for the Advancement of Artificial Intelligence (AAAI)},
   author={Besta, Maciej and Blach, Nils and Kubicek, Ales and Gerstenberger, Robert and Podstawski, Michal and Gianinazzi, Lukas and Gajda, Joanna and Lehmann, Tomasz and Niewiadomski, Hubert and Nyczyk, Piotr and Hoefler, Torsten},
   year={2024},
   month=mar, pages={17682–17690} }
@misc{madaan2023selfrefine,
      title={Self-Refine: Iterative Refinement with Self-Feedback}, 
      author={Aman Madaan and Niket Tandon and Prakhar Gupta and Skyler Hallinan and Luyu Gao and Sarah Wiegreffe and Uri Alon and Nouha Dziri and Shrimai Prabhumoye and Yiming Yang and Shashank Gupta and Bodhisattwa Prasad Majumder and Katherine Hermann and Sean Welleck and Amir Yazdanbakhsh and Peter Clark},
      year={2023},
      eprint={2303.17651},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{yang2024social,
      title={Social Skill Training with Large Language Models}, 
      author={Diyi Yang and Caleb Ziems and William Held and Omar Shaikh and Michael S. Bernstein and John Mitchell},
      year={2024},
      eprint={2404.04204},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{kuhne2020standardized,
  title={Standardized patients in psychotherapy training and clinical supervision: study protocol for a randomized controlled trial},
  author={K{\"u}hne, Franziska and Heinze, Peter Eric and Weck, Florian},
  journal={Trials},
  volume={21},
  pages={1--7},
  year={2020},
  publisher={Springer}
}
% 
@article{benjamini1995controlling,
  title={Controlling the False Discovery Rate: a Practical and Powerful Approach to Multiple Testing},
  author={Benjamini, Yoav and Hochberg, Yosef},
  journal={Journal of the Royal Statistical Society: Series B (Methodological)},
  volume={57},
  number={1},
  pages={289--300},
  year={1995},
  publisher={Wiley Online Library}
}


@misc{bubeck2023sparks,
      title={Sparks of Artificial General Intelligence: Early experiments with GPT-4}, 
      author={Sébastien Bubeck and Varun Chandrasekaran and Ronen Eldan and Johannes Gehrke and Eric Horvitz and Ece Kamar and Peter Lee and Yin Tat Lee and Yuanzhi Li and Scott Lundberg and Harsha Nori and Hamid Palangi and Marco Tulio Ribeiro and Yi Zhang},
      year={2023},
      eprint={2303.12712},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{yao2023collie,
      title={COLLIE: Systematic Construction of Constrained Text Generation Tasks}, 
      author={Shunyu Yao and Howard Chen and Austin W. Hanjie and Runzhe Yang and Karthik Narasimhan},
      year={2023},
      eprint={2307.08689},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
# need a self critique citation that that isn't about external tools?
@misc{gou2023critic,
      title={CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing}, 
      author={Zhibin Gou and Zhihong Shao and Yeyun Gong and Yelong Shen and Yujiu Yang and Nan Duan and Weizhu Chen},
      year={2023},
      eprint={2305.11738},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
% automatic generation of principles from Teacher LLM Model evaluating errors 
@misc{wang2024tpd,
      title={TPD: Enhancing Student Language Model Reasoning via Principle Discovery and Guidance}, 
      author={Haorui Wang and Rongzhi Zhang and Yinghao Li and Lingkai Kong and Yuchen Zhuang and Xiusi Chen and Chao Zhang},
      year={2024},
      eprint={2401.13849},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{sripada2005evaluation,
  title={Evaluation of an NLG system using post-edit data: Lessons learnt},
  author={Sripada, Somayajulu and Reiter, Ehud and Hawizy, Lezan},
  booktitle={Proceedings of the Tenth European Workshop on Natural Language Generation (ENLG-05)},
  year={2005}
}


@article{himmelbauer2018standardized,
  title={Standardized patients in psychiatry--the best way to learn clinical skills?},
  author={Himmelbauer, Monika and Seitz, Tamara and Seidman, Charles and L{\"o}ffler-Stastka, Henriette},
  journal={BMC medical education},
  volume={18},
  pages={1--6},
  year={2018},
  publisher={Springer}
}

@article{lakens2013calculating,
  title={Calculating and reporting effect sizes to facilitate cumulative science: a practical primer for t-tests and ANOVAs},
  author={Lakens, Dani{\"e}l},
  journal={Frontiers in psychology},
  volume={4},
  pages={62627},
  year={2013},
  publisher={Frontiers}
}

@article{braun2006thematicanalysis,
author = {Virginia Braun and Victoria Clarke},
title = {Using thematic analysis in psychology},
journal = {Qualitative Research in Psychology},
volume = {3},
number = {2},
pages = {77--101},
year = {2006},
publisher = {Routledge},
doi = {10.1191/1478088706qp063oa},
URL = {https://www.tandfonline.com/doi/abs/10.1191/1478088706qp063oa},
eprint = {https://www.tandfonline.com/doi/pdf/10.1191/1478088706qp063oa}
}


@inproceedings{
ling2023deductive,
title={Deductive Verification of Chain-of-Thought Reasoning},
author={Zhan Ling and Yunhao Fang and Xuanlin Li and Zhiao Huang and Mingu Lee and Roland Memisevic and Hao Su},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=I5rsM4CY2z}
}

@inproceedings{weng-etal-2023-large,
    title = "Large Language Models are Better Reasoners with Self-Verification",
    author = "Weng, Yixuan  and
      Zhu, Minjun  and
      Xia, Fei  and
      Li, Bin  and
      He, Shizhu  and
      Liu, Shengping  and
      Sun, Bin  and
      Liu, Kang  and
      Zhao, Jun",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.167",
    doi = "10.18653/v1/2023.findings-emnlp.167",
    pages = "2550--2575",
    abstract = "Recently, with the chain of thought (CoT) prompting, large language models (LLMs), e.g., GPT-3, have shown strong reasoning ability in several natural language processing tasks such as arithmetic, commonsense, and logical reasoning. However, LLMs with CoT require multi-step prompting and multi-token prediction, which is highly sensitive to individual mistakes and vulnerable to error accumulation. The above issues make the LLMs need the ability to verify the answers. In fact, after inferring conclusions in some thinking decision tasks, people often check them by re-verifying steps to avoid some mistakes. In this paper, we propose and prove that LLMs also have similar self-verification abilities. We take the conclusion obtained by CoT as one of the conditions for solving the original problem. By performing a backward verification of the answers that LLM deduced for itself, we can obtain interpretable answer validation scores to select the candidate answer with the highest score. Experimental results demonstrate that the proposed method can improve the reasoning performance on various arithmetic, commonsense, and logical reasoning datasets. Our code is publicly available at: https://github.com/WENGSYX/Self-Verification.",
}
@misc{lin2024imbue,
      title={IMBUE: Improving Interpersonal Effectiveness through Simulation and Just-in-time Feedback with Human-Language Model Interaction}, 
      author={Inna Wanyin Lin and Ashish Sharma and Christopher Michael Rytting and Adam S. Miner and Jina Suh and Tim Althoff},
      year={2024},
      eprint={2402.12556},
      archivePrefix={arXiv},
      primaryClass={cs.HC}
}
@article{pan2023automatically,
  title={Automatically correcting large language models: Surveying the landscape of diverse self-correction strategies},
  author={Pan, Liangming and Saxon, Michael and Xu, Wenda and Nathani, Deepak and Wang, Xinyi and Wang, William Yang},
  journal={arXiv preprint arXiv:2308.03188},
  year={2023}
}

@inproceedings{wang2023selfconsistency,
  title={Self-Consistency Improves Chain of Thought Reasoning in Language Models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc V and Chi, Ed H and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  booktitle={International Conference on Learning Representations},
  year={2023},
  url={https://iclr.cc/virtual/2023/poster/11718}
}

@article{wang2023step,
  title={Step-by-Step Remediation of Students' Mathematical Mistakes},
  author={Wang, Rose E and Zhang, Qingyang and Robinson, Carly and Loeb, Susanna and Demszky, Dorottya},
  journal={arXiv preprint arXiv:2310.10648},
  year={2023}
}

@misc{cui2023ultrafeedback,
      title={UltraFeedback: Boosting Language Models with High-quality Feedback}, 
      author={Ganqu Cui and Lifan Yuan and Ning Ding and Guanming Yao and Wei Zhu and Yuan Ni and Guotong Xie and Zhiyuan Liu and Maosong Sun},
      year={2023},
      eprint={2310.01377},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{an2023learning,
  title={Learning from mistakes makes llm better reasoner},
  author={An, Shengnan and Ma, Zexiong and Lin, Zeqi and Zheng, Nanning and Lou, Jian-Guang and Chen, Weizhu},
  journal={arXiv preprint arXiv:2310.20689},
  year={2023}
}

@article{scheurer2023training,
  title={Training language models with language feedback at scale},
  author={Scheurer, J{\'e}r{\'e}my and Campos, Jon Ander and Korbak, Tomasz and Chan, Jun Shern and Chen, Angelica and Cho, Kyunghyun and Perez, Ethan},
  journal={arXiv preprint arXiv:2303.16755},
  year={2023}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@incollection{wilcoxon1992individual,
  title={Individual comparisons by ranking methods},
  author={Wilcoxon, Frank},
  booktitle={Breakthroughs in Statistics: Methodology and Distribution},
  pages={196--202},
  year={1992},
  publisher={Springer}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@inproceedings{Achiam2023GPT4TR,
  title={GPT-4 Technical Report},
  author={OpenAI},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:257532815}
}

@article{kuzman2023chatgpt,
  title={Chatgpt: beginning of an end of manual annotation? Use case of automatic genre identification},
  author={Kuzman, Taja and Ljube{\v{s}}i{\'c}, Nikola and Mozeti{\v{c}}, Igor},
  journal={arXiv preprint arXiv:2303.03953},
  year={2023}
}

@article{gilardi2023chatgpt,
  title={Chatgpt outperforms crowd-workers for text-annotation tasks},
  author={Gilardi, Fabrizio and Alizadeh, Meysam and Kubli, Ma{\"e}l},
  journal={arXiv preprint arXiv:2303.15056},
  year={2023}
}

@inproceedings{li-etal-2023-coannotating,
    title = "{C}o{A}nnotating: Uncertainty-Guided Work Allocation between Human and Large Language Models for Data Annotation",
    author = "Li, Minzhi  and
      Shi, Taiwei  and
      Ziems, Caleb  and
      Kan, Min-Yen  and
      Chen, Nancy  and
      Liu, Zhengyuan  and
      Yang, Diyi",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.92",
    doi = "10.18653/v1/2023.emnlp-main.92",
    pages = "1487--1505",
    abstract = "Annotated data plays a critical role in Natural Language Processing (NLP) in training models and evaluating their performance. Given recent developments in Large Language Models (LLMs), models such as ChatGPT demonstrate zero-shot capability on many text-annotation tasks, comparable with or even exceeding human annotators. Such LLMs can serve as alternatives for manual annotation, due to lower costs and higher scalability. However, limited work has leveraged LLMs as complementary annotators, nor explored how annotation work is best allocated among humans and LLMs to achieve both quality and cost objectives. We propose CoAnnotating, a novel paradigm for Human-LLM co-annotation of unstructured texts at scale. Under this framework, we utilize uncertainty to estimate LLMs{'} annotation capability. Our empirical study shows CoAnnotating to be an effective means to allocate work from results on different datasets, with up to 21{\%} performance improvement over random baseline. For code implementation, see https://github.com/SALT-NLP/CoAnnotating.",
}

@article{day1980structuring,
  title={Structuring the Counseling Process.},
  author={Day, Robert W and Sparacio, Richard T},
  journal={Personnel \& Guidance Journal},
  volume={59},
  number={4},
  year={1980}
}

@article{elliott2018therapist,
  title={Therapist empathy and client outcome: An updated meta-analysis.},
  author={Elliott, Robert and Bohart, Arthur C and Watson, Jeanne C and Murphy, David},
  journal={Psychotherapy},
  volume={55},
  number={4},
  pages={399},
  year={2018},
  publisher={Educational Publishing Foundation}
}

@article{henretty2010role,
  title={The role of therapist self-disclosure in psychotherapy: A qualitative review},
  author={Henretty, Jennifer R and Levitt, Heidi M},
  journal={Clinical psychology review},
  volume={30},
  number={1},
  pages={63--77},
  year={2010},
  publisher={Elsevier}
}

@article{linehan1997validation,
  title={Validation and psychotherapy.},
  author={Linehan, Marsha M},
  year={1997},
  publisher={American Psychological Association}
}

@article{rautalinko2007reflective,
  title={Reflective listening in counseling: effects of training time and evaluator social skills},
  author={Rautalinko, Erik and Lisper, Hans-Olof and Ekehammar, Bo},
  journal={American journal of psychotherapy},
  volume={61},
  number={2},
  pages={191--209},
  year={2007},
  publisher={Am Psychiatric Assoc}
}

@article{james2010science,
  title={The science and art of asking questions in cognitive therapy},
  author={James, Ian Andrew and Morse, Rachel and Howarth, Alan},
  journal={Behavioural and Cognitive Psychotherapy},
  volume={38},
  number={1},
  pages={83--93},
  year={2010},
  publisher={Cambridge University Press}
}

@article{fang2023makes,
  title={What Makes Digital Support Effective? How Therapeutic Skills Affect Clinical Well-Being},
  author={Fang, Anna and Yang, Wenjie and Shah, Raj Sanjay and Mathur, Yash and Yang, Diyi and Zhu, Haiyi and Kraut, Robert},
  journal={arXiv preprint arXiv:2312.10775},
  year={2023}
}

@article{arnold2014behind,
  title={Behind the mirror: Reflective listening and its tain in the work of Carl Rogers},
  author={Arnold, Kyle},
  journal={The Humanistic Psychologist},
  volume={42},
  number={4},
  pages={354--369},
  year={2014},
  publisher={Taylor \& Francis}
}

@article{butler2013explanation,
  title={Explanation feedback is better than correct answer feedback for promoting transfer of learning.},
  author={Butler, Andrew C and Godbole, Namrata and Marsh, Elizabeth J},
  journal={Journal of Educational Psychology},
  volume={105},
  number={2},
  pages={290},
  year={2013},
  publisher={American Psychological Association}
}

@book{watkins2014wiley,
  title={The Wiley international handbook of clinical supervision},
  author={Watkins Jr, C Edward and Milne, Derek L},
  year={2014},
  publisher={John Wiley \& Sons}
}


@Article{fi15030110,
AUTHOR = {Wu, Zixiu and Balloccu, Simone and Kumar, Vivek and Helaoui, Rim and Reforgiato Recupero, Diego and Riboni, Daniele},
TITLE = {Creation, Analysis and Evaluation of AnnoMI, a Dataset of Expert-Annotated Counselling Dialogues},
JOURNAL = {Future Internet},
VOLUME = {15},
YEAR = {2023},
NUMBER = {3},
ARTICLE-NUMBER = {110},
URL = {https://www.mdpi.com/1999-5903/15/3/110},
ISSN = {1999-5903},
ABSTRACT = {Research on the analysis of counselling conversations through natural language processing methods has seen remarkable growth in recent years. However, the potential of this field is still greatly limited by the lack of access to publicly available therapy dialogues, especially those with expert annotations, but it has been alleviated thanks to the recent release of AnnoMI, the first publicly and freely available conversation dataset of 133 faithfully transcribed and expert-annotated demonstrations of high- and low-quality motivational interviewing (MI)&mdash;an effective therapy strategy that evokes client motivation for positive change. In this work, we introduce new expert-annotated utterance attributes to AnnoMI and describe the entire data collection process in more detail, including dialogue source selection, transcription, annotation, and post-processing. Based on the expert annotations on key MI aspects, we carry out thorough analyses of AnnoMI with respect to counselling-related properties on the utterance, conversation, and corpus levels. Furthermore, we introduce utterance-level prediction tasks with potential real-world impacts and build baseline models. Finally, we examine the performance of the models on dialogues of different topics and probe the generalisability of the models to unseen topics.},
DOI = {10.3390/fi15030110}
}

@article{borders2005new,
  title={The new handbook of counseling supervision.},
  author={Borders, L DiAnne and Brown, Lori L},
  year={2005},
  publisher={Lawrence Erlbaum Associates Publishers}
}

@article{chiu2024computational,
  title={A Computational Framework for Behavioral Assessment of LLM Therapists},
  author={Chiu, Yu Ying and Sharma, Ashish and Lin, Inna Wanyin and Althoff, Tim},
  journal={arXiv preprint arXiv:2401.00820},
  year={2024}
}

@article{althoff2016large,
  title={Large-scale analysis of counseling conversations: An application of natural language processing to mental health},
  author={Althoff, Tim and Clark, Kevin and Leskovec, Jure},
  journal={Transactions of the Association for Computational Linguistics},
  volume={4},
  pages={463--476},
  year={2016},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@book{cox1999guide,
  title={A guide to peer counseling},
  author={Cox, Jewel Rumley},
  year={1999},
  publisher={Jason Aronson}
}

@misc{association2005aca,
  title={ACA code of ethics},
  author={Association, American Counseling},
  year={2005},
  publisher={Author Alexandria, VA}
}

@article{cooper2020mindfulness,
  title={Mindfulness and empathy among counseling and psychotherapy professionals: A systematic review and meta-analysis},
  author={Cooper, David and Yap, Keong and O’Brien, Maureen and Scott, India},
  journal={Mindfulness},
  volume={11},
  pages={2243--2257},
  year={2020},
  publisher={Springer}
}

@book{herlihy2014boundary,
  title={Boundary issues in counseling: Multiple roles and responsibilities},
  author={Herlihy, Barbara and Corey, Gerald},
  year={2014},
  publisher={John Wiley \& Sons}
}

@book{hill2009helping,
  title={Helping skills: Facilitating, exploration, insight, and action},
  author={Hill, Clara E},
  year={2009},
  publisher={American Psychological Association}
}


@book{bugental2001handbook,
  title={The handbook of humanistic psychology: Leading edges in theory, research, and practice},
  author={Bugental, James FT and Pierson, J Fraser and Schneider, Kirk J},
  year={2001},
  publisher={Sage Publications}
}

@article{hsu2023helping,
  title={Helping the Helper: Supporting Peer Counselors via AI-Empowered Practice and Feedback},
  author={Hsu, Shang-Ling and Shah, Raj Sanjay and Senthil, Prathik and Ashktorab, Zahra and Dugan, Casey and Geyer, Werner and Yang, Diyi},
  journal={arXiv preprint arXiv:2305.08982},
  year={2023}
}

@article{sharma2023human,
  title={Human--AI collaboration enables more empathic conversations in text-based peer-to-peer mental health support},
  author={Sharma, Ashish and Lin, Inna W and Miner, Adam S and Atkins, David C and Althoff, Tim},
  journal={Nature Machine Intelligence},
  volume={5},
  number={1},
  pages={46--57},
  year={2023},
  publisher={Nature Publishing Group UK London}
}




@article{flemotomos2021automated,
  title={Automated quality assessment of cognitive behavioral therapy sessions through highly contextualized language representations},
  author={Flemotomos, Nikolaos and Martinez, Victor R and Chen, Zhuohao and Creed, Torrey A and Atkins, David C and Narayanan, Shrikanth},
  journal={PloS one},
  volume={16},
  number={10},
  pages={e0258639},
  year={2021},
  publisher={Public Library of Science San Francisco, CA USA}
}

@inproceedings{min-etal-2022-pair,
    title = "{PAIR}: Prompt-Aware marg{I}n Ranking for Counselor Reflection Scoring in Motivational Interviewing",
    author = "Min, Do June  and
      P{\'e}rez-Rosas, Ver{\'o}nica  and
      Resnicow, Kenneth  and
      Mihalcea, Rada",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.11",
    doi = "10.18653/v1/2022.emnlp-main.11",
    pages = "148--158",
    abstract = "Counselor reflection is a core verbal skill used by mental health counselors to express understanding and affirmation of the client{'}s experience and concerns. In this paper, we propose a system for the analysis of counselor reflections. Specifically, our system takes as input one dialog turn containing a client prompt and a counselor response, and outputs a score indicating the level of reflection in the counselor response. We compile a dataset consisting of different levels of reflective listening skills, and propose the Prompt-Aware margIn Ranking (PAIR) framework that contrasts positive and negative prompt and response pairs using specially designed multi-gap and prompt-aware margin ranking losses. Through empirical evaluations and deployment of our system in a real-life educational environment, we show that our analysis model outperforms several baselines on different metrics, and can be used to provide useful feedback to counseling trainees.",
}

@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}

@inproceedings{chen2020multi,
  title={Multi-View Sequence-to-Sequence Models with Conversational Structure for Abstractive Dialogue Summarization},
  author={Chen, Jiaao and Yang, Diyi},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={4106--4118},
  year={2020}
}

@inproceedings{choi2000advances,
  title={Advances in domain independent linear text segmentation},
  author={Choi, Freddy YY},
  booktitle={Proceedings of the 1st North American chapter of the Association for Computational Linguistics conference},
  pages={26--33},
  year={2000}
}
@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{atkins2014scaling,
  title={Scaling up the evaluation of psychotherapy: evaluating motivational interviewing fidelity via statistical text classification},
  author={Atkins, David C and Steyvers, Mark and Imel, Zac E and Smyth, Padhraic},
  journal={Implementation Science},
  volume={9},
  number={1},
  pages={1--11},
  year={2014},
  publisher={BioMed Central}
}

@article{terry2017thematic,
  title={Thematic analysis},
  author={Terry, Gareth and Hayfield, Nikki and Clarke, Victoria and Braun, Virginia},
  journal={The SAGE handbook of qualitative research in psychology},
  volume={2},
  pages={17--37},
  year={2017},
  publisher={SAGE Publishers}
}


@article{7cups2023,
  title={7Cups Verfiers Team Mock Chat Guide: Discussing Points That Need Improvement},
  author={team 7Cups},
  year={2023}
}

@misc{7cupswebsite,
    title={7 Cups: Free Online Therapist and Counseling},
    author={7Cups},
    year={2024},
    addendum = {(accessed: 04.11.2024)}
}

@article{nurse2024influence,
  title={The influence of deliberate practice on skill performance in therapeutic practice: A systematic review of early studies},
  author={Nurse, Karina and O’shea, Melissa and Ling, Mathew and Castle, Nathan and Sheen, Jade},
  journal={Psychotherapy Research},
  pages={1--15},
  year={2024},
  publisher={Taylor \& Francis}
}
@techreport{gliva2020comprehensive,
  title={Comprehensive healthcare simulation: implementing best practices in standardized patient methodology},
  author={Gliva-McConvey, Gayle and Nicholas, Catherine F and Clark, Lou and others},
  year={2020},
  institution={Springer}
}


% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INCOLLECTION{Karen2017-fp,
  title     = "Contextual inquiry: A participatory technique for system design",
  booktitle = "Participatory design",
  author    = "Karen, Holtzblatt and Sandra, Jones",
  abstract  = "Our goal in system design is to support, extend, and positively
               transform the work of individuals, teams and businesses through
               computer systems. We use the term system to refer to a …",
  publisher = "CRC Press",
  pages     = "177--210",
  year      =  2017
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Nicol2006-dj,
  title     = "Formative assessment and self‐regulated learning: a model and
               seven principles of good feedback practice",
  author    = "Nicol, David J and Macfarlane‐Dick, Debra",
  abstract  = "The research on formative assessment and feedback is
               reinterpreted to show how these processes can help students take
               control of their own learning, i.e. become self?regulated
               learners. This reformulation is used to identify seven
               principles of good feedback practice that support
               self?regulation. A key argument is that students are already
               assessing their own work and generating their own feedback, and
               that higher education should build on this ability. The research
               underpinning each feedback principle is presented, and some
               examples of easy?to?implement feedback strategies are briefly
               described. This shift in focus, whereby students are seen as
               having a proactive rather than a reactive role in generating and
               using feedback, has profound implications for the way in which
               teachers organise assessments and support learning.",
  journal   = "Studies in Higher Education",
  publisher = "Routledge",
  volume    =  31,
  number    =  2,
  pages     = "199--218",
  month     =  apr,
  year      =  2006
}



@ARTICLE{rehearsal,
  title    = "Rehearsal: Simulating Conflict to Teach Conflict Resolution",
  author   = "Shaikh, Omar and Chai, Valentino and Gelfand, Michele J and Yang,
              Diyi and Bernstein, Michael S",
  abstract = "Interpersonal conflict is an uncomfortable but unavoidable fact
              of life. Navigating conflict successfully is a skill -- one that
              can be learned through deliberate practice -- but few have access
              to effective training or feedback. To expand this access, we
              introduce Rehearsal, a system that allows users to rehearse
              conflicts with a believable simulated interlocutor, explore
              counterfactual ``what if?'' scenarios to identify alternative
              conversational paths, and learn through feedback on how and when
              to apply specific conflict strategies. Users can utilize
              Rehearsal to practice handling a variety of predefined conflict
              scenarios, from office disputes to relationship issues, or they
              can choose to create their own. To enable Rehearsal, we develop
              IRP prompting, a method of conditioning output of a large
              language model on the influential Interest-Rights-Power (IRP)
              theory from conflict resolution. Rehearsal uses IRP to generate
              utterances grounded in conflict resolution theory, guiding users
              towards counterfactual conflict resolution strategies that help
              de-escalate difficult conversations. In a between-subjects
              evaluation, 40 participants engaged in an actual conflict with a
              confederate after training. Compared to a control group with
              lecture material covering the same IRP theory, participants with
              simulated training from Rehearsal significantly improved their
              performance in the unaided conflict: they reduced their use of
              escalating competitive strategies by an average of 67\%, while
              doubling their use of cooperative strategies. Overall, Rehearsal
              highlights the potential effectiveness of language models as
              tools for learning and practicing interpersonal skills.",
  journal  = "arXiv [cs.HC]",
  month    =  sep,
  year     =  2023
}



@ARTICLE{Wheeler2007-zh,
  title     = "The impact of clinical supervision on counsellors and
               therapists, their practice and their clients. A systematic
               review of the literature",
  author    = "Wheeler, Sue and Richards, Kaye",
  abstract  = "In 2005 the British Association for Counselling and
               Psychotherapy (BACP) commissioned a systematic review of the
               research evidence related to the impact of supervision on
               counsellors and psychotherapists, their practice and their
               clients. This paper reports on some of the findings of this
               review, specifically from articles published in this area since
               1980. Detailed inclusion and exclusion criteria were agreed.
               EPPI-Reviewer software was used to organise and analyse the
               articles that met the inclusion criteria. This article reviews
               18 individual published studies. The quality of evidence is
               variable, but supervision is consistently demonstrated to have
               some positive impacts on the supervisee.",
  journal   = "Counselling and Psychotherapy Research",
  publisher = "Routledge",
  volume    =  7,
  number    =  1,
  pages     = "54--65",
  month     =  mar,
  year      =  2007
}


@ARTICLE{llama,
  title         = "{LLaMA}: Open and Efficient Foundation Language Models",
  author        = "Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and
                   Martinet, Xavier and Lachaux, Marie-Anne and Lacroix,
                   Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and
                   Hambro, Eric and Azhar, Faisal and Rodriguez, Aurelien and
                   Joulin, Armand and Grave, Edouard and Lample, Guillaume",
  abstract      = "We introduce LLaMA, a collection of foundation language
                   models ranging from 7B to 65B parameters. We train our
                   models on trillions of tokens, and show that it is possible
                   to train state-of-the-art models using publicly available
                   datasets exclusively, without resorting to proprietary and
                   inaccessible datasets. In particular, LLaMA-13B outperforms
                   GPT-3 (175B) on most benchmarks, and LLaMA-65B is
                   competitive with the best models, Chinchilla-70B and
                   PaLM-540B. We release all our models to the research
                   community.",
  month         =  feb,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2302.13971"
}

@inproceedings{
lora,
title={Lo{RA}: Low-Rank Adaptation of Large Language Models},
author={Edward J Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=nZeVKeeFYf9}
}

@ARTICLE{qlora,
  title         = "{QLoRA}: Efficient Finetuning of Quantized {LLMs}",
  author        = "Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and
                   Zettlemoyer, Luke",
  abstract      = "We present QLoRA, an efficient finetuning approach that
                   reduces memory usage enough to finetune a 65B parameter
                   model on a single 48GB GPU while preserving full 16-bit
                   finetuning task performance. QLoRA backpropagates gradients
                   through a frozen, 4-bit quantized pretrained language model
                   into Low Rank Adapters~(LoRA). Our best model family, which
                   we name Guanaco, outperforms all previous openly released
                   models on the Vicuna benchmark, reaching 99.3\% of the
                   performance level of ChatGPT while only requiring 24 hours
                   of finetuning on a single GPU. QLoRA introduces a number of
                   innovations to save memory without sacrificing performance:
                   (a) 4-bit NormalFloat (NF4), a new data type that is
                   information theoretically optimal for normally distributed
                   weights (b) double quantization to reduce the average memory
                   footprint by quantizing the quantization constants, and (c)
                   paged optimziers to manage memory spikes. We use QLoRA to
                   finetune more than 1,000 models, providing a detailed
                   analysis of instruction following and chatbot performance
                   across 8 instruction datasets, multiple model types (LLaMA,
                   T5), and model scales that would be infeasible to run with
                   regular finetuning (e.g. 33B and 65B parameter models). Our
                   results show that QLoRA finetuning on a small high-quality
                   dataset leads to state-of-the-art results, even when using
                   smaller models than the previous SoTA. We provide a detailed
                   analysis of chatbot performance based on both human and
                   GPT-4 evaluations showing that GPT-4 evaluations are a cheap
                   and reasonable alternative to human evaluation. Furthermore,
                   we find that current chatbot benchmarks are not trustworthy
                   to accurately evaluate the performance levels of chatbots. A
                   lemon-picked analysis demonstrates where Guanaco fails
                   compared to ChatGPT. We release all of our models and code,
                   including CUDA kernels for 4-bit training.",
  month         =  may,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG",
  eprint        = "2305.14314"
}

@ARTICLE{lima,
  title         = "{LIMA}: Less Is More for Alignment",
  author        = "Zhou, Chunting and Liu, Pengfei and Xu, Puxin and Iyer,
                   Srini and Sun, Jiao and Mao, Yuning and Ma, Xuezhe and
                   Efrat, Avia and Yu, Ping and Yu, Lili and Zhang, Susan and
                   Ghosh, Gargi and Lewis, Mike and Zettlemoyer, Luke and Levy,
                   Omer",
  abstract      = "Large language models are trained in two stages: (1)
                   unsupervised pretraining from raw text, to learn
                   general-purpose representations, and (2) large scale
                   instruction tuning and reinforcement learning, to better
                   align to end tasks and user preferences. We measure the
                   relative importance of these two stages by training LIMA, a
                   65B parameter LLaMa language model fine-tuned with the
                   standard supervised loss on only 1,000 carefully curated
                   prompts and responses, without any reinforcement learning or
                   human preference modeling. LIMA demonstrates remarkably
                   strong performance, learning to follow specific response
                   formats from only a handful of examples in the training
                   data, including complex queries that range from planning
                   trip itineraries to speculating about alternate history.
                   Moreover, the model tends to generalize well to unseen tasks
                   that did not appear in the training data. In a controlled
                   human study, responses from LIMA are either equivalent or
                   strictly preferred to GPT-4 in 43\% of cases; this statistic
                   is as high as 58\% when compared to Bard and 65\% versus
                   DaVinci003, which was trained with human feedback. Taken
                   together, these results strongly suggest that almost all
                   knowledge in large language models is learned during
                   pretraining, and only limited instruction tuning data is
                   necessary to teach models to produce high quality output.",
  month         =  may,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2305.11206"
}


@ARTICLE{gpt4,
  title         = "{GPT-4} Technical Report",
  author        = "{OpenAI}",
  abstract      = "We report the development of GPT-4, a large-scale,
                   multimodal model which can accept image and text inputs and
                   produce text outputs. While less capable than humans in many
                   real-world scenarios, GPT-4 exhibits human-level performance
                   on various professional and academic benchmarks, including
                   passing a simulated bar exam with a score around the top
                   10\% of test takers. GPT-4 is a Transformer-based model
                   pre-trained to predict the next token in a document. The
                   post-training alignment process results in improved
                   performance on measures of factuality and adherence to
                   desired behavior. A core component of this project was
                   developing infrastructure and optimization methods that
                   behave predictably across a wide range of scales. This
                   allowed us to accurately predict some aspects of GPT-4's
                   performance based on models trained with no more than
                   1/1,000th the compute of GPT-4.",
  month         =  mar,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2303.08774"
}


@ARTICLE{heiley,
  title     = "{Human--AI} collaboration enables more empathic conversations in
               text-based peer-to-peer mental health support",
  author    = "Sharma, Ashish and Lin, Inna W and Miner, Adam S and Atkins,
               David C and Althoff, Tim",
  abstract  = "Advances in artificial intelligence (AI) are enabling systems
               that augment and collaborate with humans to perform simple,
               mechanistic tasks such as scheduling meetings and
               grammar-checking text. However, such human--AI collaboration
               poses challenges for more complex tasks, such as carrying out
               empathic conversations, due to the difficulties that AI systems
               face in navigating complex human emotions and the open-ended
               nature of these tasks. Here we focus on peer-to-peer mental
               health support, a setting in which empathy is critical for
               success, and examine how AI can collaborate with humans to
               facilitate peer empathy during textual, online supportive
               conversations. We develop HAILEY, an AI-in-the-loop agent that
               provides just-in-time feedback to help participants who provide
               support (peer supporters) respond more empathically to those
               seeking help (support seekers). We evaluate HAILEY in a
               non-clinical randomized controlled trial with real-world peer
               supporters on TalkLife (N = 300), a large online peer-to-peer
               support platform. We show that our human--AI collaboration
               approach leads to a 19.6\% increase in conversational empathy
               between peers overall. Furthermore, we find a larger, 38.9\%
               increase in empathy within the subsample of peer supporters who
               self-identify as experiencing difficulty providing support. We
               systematically analyse the human--AI collaboration patterns and
               find that peer supporters are able to use the AI feedback both
               directly and indirectly without becoming overly reliant on AI
               while reporting improved self-efficacy post-feedback. Our
               findings demonstrate the potential of feedback-driven,
               AI-in-the-loop writing systems to empower humans in open-ended,
               social and high-stakes tasks such as empathic conversations. AI
               language modelling and generation approaches have developed fast
               in the last decade, opening promising new directions in
               human--AI collaboration. An AI-in-the loop conversational system
               called HAILEY is developed to empower peer supporters in
               providing empathic responses to mental health support seekers.",
  journal   = "Nature Machine Intelligence",
  publisher = "Nature Publishing Group",
  volume    =  5,
  number    =  1,
  pages     = "46--57",
  month     =  jan,
  year      =  2023,
  language  = "en"
}


@ARTICLE{care,
  title         = "Helping the Helper: Supporting Peer Counselors via
                   {AI-Empowered} Practice and Feedback",
  author        = "Hsu, Shang-Ling and Shah, Raj Sanjay and Senthil, Prathik
                   and Ashktorab, Zahra and Dugan, Casey and Geyer, Werner and
                   Yang, Diyi",
  abstract      = "Millions of users come to online peer counseling platforms
                   to seek support on diverse topics ranging from relationship
                   stress to anxiety. However, studies show that online peer
                   support groups are not always as effective as expected
                   largely due to users' negative experiences with unhelpful
                   counselors. Peer counselors are key to the success of online
                   peer counseling platforms, but most of them often do not
                   have systematic ways to receive guidelines or supervision.
                   In this work, we introduce CARE: an interactive AI-based
                   tool to empower peer counselors through automatic suggestion
                   generation. During the practical training stage, CARE helps
                   diagnose which specific counseling strategies are most
                   suitable in the given context and provides tailored example
                   responses as suggestions. Counselors can choose to select,
                   modify, or ignore any suggestion before replying to the
                   support seeker. Building upon the Motivational Interviewing
                   framework, CARE utilizes large-scale counseling conversation
                   data together with advanced natural language generation
                   techniques to achieve these functionalities. We demonstrate
                   the efficacy of CARE by performing both quantitative
                   evaluations and qualitative user studies through simulated
                   chats and semi-structured interviews. We also find that CARE
                   especially helps novice counselors respond better in
                   challenging situations.",
  month         =  may,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "cs.HC",
  eprint        = "2305.08982"
}

% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {$L_1$}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
  url={https://dl.acm.org/doi/abs/10.1145/1273496.1273501}
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK},
    url={https://www.cambridge.org/core/books/algorithms-on-strings-trees-and-sequences/F0B095049C7E6EF5356F0A26686C20D3}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005},
	url={https://www.jmlr.org/papers/volume6/ando05a/ando05a.pdf}
}

@article{ct1965,
  title={An algorithm for the machine calculation of complex {F}ourier series},
  author={Cooley, James W. and Tukey, John W.},
  journal={Mathematics of Computation},
  volume={19},
  number={90},
  pages={297--301},
  year={1965},
  url={https://www.ams.org/journals/mcom/1965-19-090/S0025-5718-1965-0178586-1/S0025-5718-1965-0178586-1.pdf}
}


@inproceedings{h_ai_class_1,
author = {Bansal, Gagan and Wu, Tongshuang and Zhou, Joyce and Fok, Raymond and Nushi, Besmira and Kamar, Ece and Ribeiro, Marco Tulio and Weld, Daniel},
title = {Does the Whole Exceed Its Parts? The Effect of AI Explanations on Complementary Team Performance},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445717},
doi = {10.1145/3411764.3445717},
abstract = {Many researchers motivate explainable AI with studies showing that human-AI team performance on decision-making tasks improves when the AI explains its recommendations. However, prior studies observed improvements from explanations only when the AI, alone, outperformed both the human and the best team. Can explanations help lead to complementary performance, where team accuracy is higher than either the human or the AI working solo? We conduct mixed-method user studies on three datasets, where an AI with accuracy comparable to humans helps participants solve a task (explaining itself in some conditions). While we observed complementary improvements from AI augmentation, they were not increased by explanations. Rather, explanations increased the chance that humans will accept the AI’s recommendation, regardless of its correctness. Our result poses new challenges for human-centered AI: Can we develop explanatory approaches that encourage appropriate trust in AI, and therefore help generate (or improve) complementary performance?},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {81},
numpages = {16},
keywords = {Human-AI teams, Explainable AI, Augmented intelligence},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{h_ai_class_2,
author = {Smith-Renner, Alison and Fan, Ron and Birchfield, Melissa and Wu, Tongshuang and Boyd-Graber, Jordan and Weld, Daniel S. and Findlater, Leah},
title = {No Explainability without Accountability: An Empirical Study of Explanations and Feedback in Interactive ML},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376624},
doi = {10.1145/3313831.3376624},
abstract = {Automatically generated explanations of how machine learning (ML) models reason can help users understand and accept them. However, explanations can have unintended consequences: promoting over-reliance or undermining trust. This paper investigates how explanations shape users' perceptions of ML models with or without the ability to provide feedback to them: (1) does revealing model flaws increase users' desire to "fix" them; (2) does providing explanations cause users to believe - wrongly - that models are introspective, and will thus improve over time. Through two controlled experiments - varying model quality - we show how the combination of explanations and user feedback impacted perceptions, such as frustration and expectations of model improvement. Explanations without opportunity for feedback were frustrating with a lower quality model, while interactions between explanation and feedback for the higher quality model suggest that detailed feedback should not be requested without explanation. Users expected model correction, regardless of whether they provided feedback or received explanations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {explainable machine learning, interactive machine learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{h_ai_cw_1,
author = {Clark, Elizabeth and Ross, Anne Spencer and Tan, Chenhao and Ji, Yangfeng and Smith, Noah A.},
title = {Creative Writing with a Machine in the Loop: Case Studies on Slogans and Stories},
year = {2018},
isbn = {9781450349451},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3172944.3172983},
doi = {10.1145/3172944.3172983},
abstract = {As the quality of natural language generated by artificial intelligence systems improves, writing interfaces can support interventions beyond grammar-checking and spell-checking, such as suggesting content to spark new ideas. To explore the possibility of machine-in-the-loop creative writing, we performed two case studies using two system prototypes, one for short story writing and one for slogan writing. Participants in our studies were asked to write with a machine in the loop or alone (control condition). They assessed their writing and experience through surveys and an open-ended interview. We collected additional assessments of the writing from Amazon Mechanical Turk crowdworkers. Our findings indicate that participants found the process fun and helpful and could envision use cases for future systems. At the same time, machine suggestions do not necessarily lead to better written artifacts. We therefore suggest novel natural language models and design choices that may better support creative writing.},
booktitle = {23rd International Conference on Intelligent User Interfaces},
pages = {329–340},
numpages = {12},
keywords = {machine in the loop, creative writing, natural language processing},
location = {Tokyo, Japan},
series = {IUI '18}
}

@inproceedings{h_ai_cw_2,
author = {Gero, Katy Ilonka and Chilton, Lydia B.},
title = {Metaphoria: An Algorithmic Companion for Metaphor Creation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300526},
doi = {10.1145/3290605.3300526},
abstract = {Creative writing, from poetry to journalism, is at the crux of human ingenuity and social interaction. Existing creative writing support tools produce entire passages or fully formed sentences, but these approaches fail to adapt to the writer's own ideas and intentions. Instead we posit to build tools that generate ideas coherent with the writer's context and encourage writers to produce divergent outcomes. To explore this, we focus on supporting metaphor creation. We present Metaphoria, an interactive system that generates metaphorical connections based on an input word from the writer. Our studies show that Metaphoria provides more coherent suggestions than existing systems, and supports the expression of writers' unique intentions. We discuss the complex issue of ownership in human-machine collaboration and how to build adaptive creativity support tools in other domains.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {generative art, co-creativity, human-computer collaboration, writing support, natural language processing},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{h_ai_decision_making_1,
author = {Levy, Ariel and Agrawal, Monica and Satyanarayan, Arvind and Sontag, David},
title = {Assessing the Impact of Automated Suggestions on Decision Making: Domain Experts Mediate Model Errors but Take Less Initiative},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445522},
doi = {10.1145/3411764.3445522},
abstract = {Automated decision support can accelerate tedious tasks as users can focus their attention where it is needed most. However, a key concern is whether users overly trust or cede agency to automation. In this paper, we investigate the effects of introducing automation to annotating clinical texts&nbsp;—&nbsp;a multi-step, error-prone task of identifying clinical concepts (e.g., procedures) in medical notes, and mapping them to labels in a large ontology. We consider two forms of decision aid: recommending which labels to map concepts to, and pre-populating annotation suggestions. Through laboratory studies, we find that 18 clinicians generally build intuition of when to rely on automation and when to exercise their own judgement. However, when presented with fully pre-populated suggestions, these expert users exhibit less agency: accepting improper mentions, and taking less initiative in creating additional annotations. Our findings inform how systems and algorithms should be designed to mitigate the observed issues.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {72},
numpages = {13},
keywords = {ontology, agency, text tagging, clinical annotation, mental model, human-AI teams},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{founta2018large,
    title={Large Scale Crowdsourcing and Characterization of Twitter Abusive Behavior},
    author={Founta, Antigoni-Maria and Djouvas, Constantinos and Chatzakou, Despoina and Leontiadis, Ilias and Blackburn, Jeremy and Stringhini, Gianluca and Vakali, Athena and Sirivianos, Michael and Kourtellis, Nicolas},
    booktitle={11th International Conference on Web and Social Media, ICWSM 2018},
    year={2018},
    organization={AAAI Press}
}

@article{davidson_hate,
  author    = {Thomas Davidson and
               Dana Warmsley and
               Michael W. Macy and
               Ingmar Weber},
  title     = {Automated Hate Speech Detection and the Problem of Offensive Language},
  journal   = {CoRR},
  volume    = {abs/1703.04009},
  year      = {2017},
  url       = {http://arxiv.org/abs/1703.04009},
  eprinttype = {arXiv},
  eprint    = {1703.04009},
  timestamp = {Mon, 13 Aug 2018 16:47:34 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/DavidsonWMW17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{bing_racism,
author = {He, Bing and Ziems, Caleb and Soni, Sandeep and Ramakrishnan, Naren and Yang, Diyi and Kumar, Srijan},
title = {Racism is a Virus: Anti-Asian Hate and Counterspeech in Social Media during the COVID-19 Crisis},
year = {2022},
isbn = {9781450391283},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3487351.3488324},
doi = {10.1145/3487351.3488324},
abstract = {The spread of COVID-19 has sparked racism and hate on social media targeted towards Asian communities. However, little is known about how racial hate spreads during a pandemic and the role of counterspeech in mitigating this spread. In this work, we study the evolution and spread of anti-Asian hate speech through the lens of Twitter. We create COVID-HATE, the largest dataset of anti-Asian hate and counterspeech spanning 14 months, containing over 206 million tweets, and a social network with over 127 million nodes. By creating a novel hand-labeled dataset of 3,355 tweets, we train a text classifier to identify hateful and counterspeech tweets that achieves an average macro-F1 score of 0.832. Using this dataset, we conduct longitudinal analysis of tweets and users. Analysis of the social network reveals that hateful and counterspeech users interact and engage extensively with one another, instead of living in isolated polarized communities. We find that nodes were highly likely to become hateful after being exposed to hateful content in the year 2020. Notably, counterspeech messages discourage users from turning hateful, potentially suggesting a solution to curb hate on web and social media platforms. Data and code is available at http://claws.cc.gatech.edu/covid.},
booktitle = {Proceedings of the 2021 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {90–94},
numpages = {5},
location = {Virtual Event, Netherlands},
series = {ASONAM '21}
}

@misc{caselli2021hatebert,
      title={HateBERT: Retraining BERT for Abusive Language Detection in English}, 
      author={Tommaso Caselli and Valerio Basile and Jelena Mitrović and Michael Granitzer},
      year={2021},
      eprint={2010.12472},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}


@article{transformers,
  title={Attention is All you Need},
  author={Ashish Vaswani and Noam M. Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  journal={ArXiv},
  year={2017},
  volume={abs/1706.03762}
}


@article{roberta,
  title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},
  author={Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},
  journal={ArXiv},
  year={2019},
  volume={abs/1907.11692}
}

@inproceedings{gpt2,
  title={Language Models are Unsupervised Multitask Learners},
  author={Alec Radford and Jeff Wu and R. Child and David Luan and Dario Amodei and Ilya Sutskever},
  year={2019}
}

@inproceedings{domain2,
    title = "Don{'}t Stop Pretraining: Adapt Language Models to Domains and Tasks",
    author = "Gururangan, Suchin  and
      Marasovi{\'c}, Ana  and
      Swayamdipta, Swabha  and
      Lo, Kyle  and
      Beltagy, Iz  and
      Downey, Doug  and
      Smith, Noah A.",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.740",
    doi = "10.18653/v1/2020.acl-main.740",
    pages = "8342--8360",
}

@inproceedings{bertweet,
title     = {{BERTweet: A pre-trained language model for English Tweets}},
author    = {Dat Quoc Nguyen and Thanh Vu and Anh Tuan Nguyen},
booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
pages     = {9--14},
year      = {2020}
}


@article{muller2020covid,
  title={COVID-Twitter-BERT: A Natural Language Processing Model to Analyse COVID-19 Content on Twitter},
  author={M{\"u}ller, Martin and Salath{\'e}, Marcel and Kummervold, Per E},
  journal={arXiv preprint arXiv:2005.07503},
  year={2020}
}

@misc{textgcn,
      title={Graph Convolutional Networks for Text Classification}, 
      author={Liang Yao and Chengsheng Mao and Yuan Luo},
      year={2018},
      eprint={1809.05679},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{lin2022bertgcn,
      title={BertGCN: Transductive Text Classification by Combining GCN and BERT}, 
      author={Yuxiao Lin and Yuxian Meng and Xiaofei Sun and Qinghong Han and Kun Kuang and Jiwei Li and Fei Wu},
      year={2022},
      eprint={2105.05727},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{transformersinterpret,
    author = "Github",
    title = "Transformers Interpret",
    url  = "https://github.com/cdpierse/transformers-interpret",
    year = "2022",
    addendum = {(accessed: 03.28.2023)}
}

@inproceedings{lal-etal-2021-interpret,
    title = "{I}nterpre{T}: An Interactive Visualization Tool for Interpreting Transformers",
    author = "Lal, Vasudev  and
      Ma, Arden  and
      Aflalo, Estelle  and
      Howard, Phillip  and
      Simoes, Ana  and
      Korat, Daniel  and
      Pereg, Oren  and
      Singer, Gadi  and
      Wasserblat, Moshe",
    booktitle = "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations",
    month = apr,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.eacl-demos.17",
    doi = "10.18653/v1/2021.eacl-demos.17",
    pages = "135--142",
    abstract = "With the increasingly widespread use of Transformer-based models for NLU/NLP tasks, there is growing interest in understanding the inner workings of these models, why they are so effective at a wide range of tasks, and how they can be further tuned and improved. To contribute towards this goal of enhanced explainability and comprehension, we present InterpreT, an interactive visualization tool for interpreting Transformer-based models. In addition to providing various mechanisms for investigating general model behaviours, novel contributions made in InterpreT include the ability to track and visualize token embeddings through each layer of a Transformer, highlight distances between certain token embeddings through illustrative plots, and identify task-related functions of attention heads by using new metrics. InterpreT is a task agnostic tool, and its functionalities are demonstrated through the analysis of model behaviours for two disparate tasks: Aspect Based Sentiment Analysis (ABSA) and the Winograd Schema Challenge (WSC).",
}

% Please download the latest anthology.bib from
%
% http://aclweb.org/anthology/anthology.bib.gz






@inproceedings{li2020maec,
  title={MAEC: A multimodal aligned earnings conference call dataset for financial risk prediction},
  author={Li, Jiazheng and Yang, Linyi and Smyth, Barry and Dong, Ruihai},
  booktitle={Proceedings of the 29th ACM International Conference on Information \& Knowledge Management},
  pages={3063--3070},
  year={2020}
}




@inproceedings{qin2019you,
  title={What you say and how you say it matters: Predicting stock volatility using verbal and vocal cues},
  author={Qin, Yu and Yang, Yi},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={390--401},
  year={2019}
}



@article{chava2020ESG,
  title={Do Managers Walk the Talk on Environmental and Social Issues?},
  author={Chava, Sudheer and Du, Wendi and Malakar, Baridhi},
  year={2020}
}


@article{transformer,
  title={Attention is All you Need},
  author={Ashish Vaswani and Noam M. Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  journal={ArXiv},
  year={2017},
  volume={abs/1706.03762}
}

@inproceedings{sawhney2020voltage,
  title={VolTAGE: volatility forecasting via text-audio fusion with graph convolution networks for earnings calls},
  author={Sawhney, Ramit and Khanna, Piyush and Aggarwal, Arshiya and Jain, Taru and Mathur, Puneet and Shah, Rajiv},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={8001--8013},
  year={2020}
}

@article{francis2019transfer,
  title={Transfer learning for named entity recognition in financial and biomedical documents},
  author={Francis, Sumam and Van Landeghem, Jordy and Moens, Marie-Francine},
  journal={Information},
  volume={10},
  number={8},
  pages={248},
  year={2019},
  publisher={Multidisciplinary Digital Publishing Institute}
}

% Please download the latest anthology.bib from
%
% http://aclweb.org/anthology/anthology.bib.gz
% Please download the latest anthology.bib from
%
% http://aclweb.org/anthology/anthology.bib.gz

@misc{fiqa,
  title={Financial Question Answering},
  author={FiQA},
  howpublished={\url{https://sites.google.com/view/fiqa}}
}

@misc{finsbd3,
  title={Financial SBD 3},
  author={FinSBD3},
  year={2021},
  howpublished={\url{https://sites.google.com/nlg.csie.ntu.edu.tw/finweb2021/shared-task-finsbd-3}}
}

@misc{leaderboard,
  title={Financial SBD 3 Leaderboard},
  author={LeaderBoard},
  howpublished={\url{https://competitions.codalab.org/competitions/28485#results}}
}

@misc{ndcg,
  title={Rank-Aware Top-N Metrics},
  author={Michael,Ekstrand and Joseph,Konstan},
  howpublished={\url{https://www.coursera.org/lecture/recommender-metrics/rank-aware-top-n-metrics-Wk98r}}
}

@article{loughran2011liability,
  title={When is a liability not a liability? Textual analysis, dictionaries, and 10-Ks},
  author={Loughran, Tim and McDonald, Bill},
  journal={The Journal of finance},
  volume={66},
  number={1},
  pages={35--65},
  year={2011},
  publisher={Wiley Online Library}
}
@article{garcia2013sentiment,
  title={Sentiment during recessions},
  author={Garcia, Diego},
  journal={The Journal of Finance},
  volume={68},
  number={3},
  pages={1267--1300},
  year={2013},
  publisher={Wiley Online Library}
}


@inproceedings{li2020maec,
  title={MAEC: A multimodal aligned earnings conference call dataset for financial risk prediction},
  author={Li, Jiazheng and Yang, Linyi and Smyth, Barry and Dong, Ruihai},
  booktitle={Proceedings of the 29th ACM International Conference on Information \& Knowledge Management},
  pages={3063--3070},
  year={2020}
}

@inproceedings{alvarado2015domain,
  title={Domain adaption of named entity recognition to support credit risk assessment},
  author={Alvarado, Julio Cesar Salinas and Verspoor, Karin and Baldwin, Timothy},
  booktitle={Proceedings of the Australasian Language Technology Association Workshop 2015},
  pages={84--90},
  year={2015}
}


@article{sinha2020impact,
  title={Impact of News on the Commodity Market: Dataset and Results},
  author={Sinha, Ankur and Khandait, Tanmay},
  journal={arXiv preprint arXiv:2009.04202},
  year={2020}
}

@inproceedings{liu2020finbert,
  title={Finbert: A pre-trained financial language representation model for financial text mining},
  author={Liu, Zhuang and Huang, Degen and Huang, Kaiyu and Li, Zhuang and Zhao, Jun},
  booktitle={Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI},
  pages={5--10},
  year={2020}
}
@article{finbert,
  author    = {Yi Yang and
               Mark Christopher Siy Uy and
               Allen Huang},
  title     = {FinBERT: {A} Pretrained Language Model for Financial Communications},
  journal   = {CoRR},
  volume    = {abs/2006.08097},
  year      = {2020},
  url       = {https://arxiv.org/abs/2006.08097},
  eprinttype = {arXiv},
  eprint    = {2006.08097},
  timestamp = {Wed, 17 Jun 2020 14:28:54 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2006-08097.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{orig_finbert,
  title={FinBERT: Financial Sentiment Analysis with Pre-trained Language Models},
  author={Dogu Araci},
  journal={ArXiv},
  year={2019},
  volume={abs/1908.10063}
}

@inproceedings{FiQA10.1145/3184558.3192301,
author = {Maia, Macedo and Handschuh, Siegfried and Freitas, Andr\'{e} and Davis, Brian and McDermott, Ross and Zarrouk, Manel and Balahur, Alexandra},
title = {WWW'18 Open Challenge: Financial Opinion Mining and Question Answering},
year = {2018},
isbn = {9781450356404},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3184558.3192301},
doi = {10.1145/3184558.3192301},
abstract = {The growing maturity of Natural Language Processing (NLP) techniques and resources is dramatically changing the landscape of many application domains which are dependent on the analysis of unstructured data at scale. The finance domain, with its reliance on the interpretation of multiple unstructured and structured data sources and its demand for fast and comprehensive decision making is already emerging as a primary ground for the experimentation of NLP, Web Mining and Information Retrieval (IR) techniques for the automatic analysis of financial news and opinions online. This challenge focuses on advancing the state-of-the-art of aspect-based sentiment analysis and opinion-based Question Answering for the financial domain.},
booktitle = {Companion Proceedings of the The Web Conference 2018},
pages = {1941–1942},
numpages = {2},
keywords = {opinion mining, financial domain, question answering},
location = {Lyon, France},
series = {WWW '18}
}

@inproceedings{qin2019you,
  title={What you say and how you say it matters: Predicting stock volatility using verbal and vocal cues},
  author={Qin, Yu and Yang, Yi},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={390--401},
  year={2019}
}

@article{chava2019buzzwords,
  title={Buzzwords?},
  author={Chava, Sudheer and Du, Wendi and Paradkar, Nikhil},
  journal={Available at SSRN 3862645},
  year={2019}
}

@article{chava2016december,
  title={December Doldrums, Investor Distraction, and Stock Market Reaction to Unscheduled News Events},
  author={Chava, Sudheer and Paradkar, Nikhil},
  journal={Available at SSRN 2962476},
  year={2016}
}




@article{electra,
  title={ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators},
  author={Kevin Clark and Minh-Thang Luong and Quoc V. Le and Christopher D. Manning},
  journal={ArXiv},
  year={2020},
  volume={abs/2003.10555}
}
@article{buehlmaier2018financial,
  title={Are financial constraints priced? Evidence from textual analysis},
  author={Buehlmaier, Matthias MM and Whited, Toni M},
  journal={The Review of Financial Studies},
  volume={31},
  number={7},
  pages={2693--2728},
  year={2018},
  publisher={Oxford University Press}
}
@article{li2010information,
  title={The information content of forward-looking statements in corporate filings—A na{\"\i}ve Bayesian machine learning approach},
  author={Li, Feng},
  journal={Journal of Accounting Research},
  volume={48},
  number={5},
  pages={1049--1102},
  year={2010},
  publisher={Wiley Online Library}
}
@article{bushee2003open,
  title={Open versus closed conference calls: the determinants and effects of broadening access to disclosure},
  author={Bushee, Brian J and Matsumoto, Dawn A and Miller, Gregory S},
  journal={Journal of accounting and economics},
  volume={34},
  number={1-3},
  pages={149--180},
  year={2003},
  publisher={Elsevier}
}
@article{bowen2002conference,
  title={Do conference calls affect analysts' forecasts?},
  author={Bowen, Robert M and Davis, Angela K and Matsumoto, Dawn A},
  journal={The Accounting Review},
  volume={77},
  number={2},
  pages={285--316},
  year={2002}
}
@article{bochkay2020hyperbole,
  title={Hyperbole or reality? Investor response to extreme language in earnings conference calls},
  author={Bochkay, Khrystyna and Hales, Jeffrey and Chava, Sudheer},
  journal={The Accounting Review},
  volume={95},
  number={2},
  pages={31--60},
  year={2020},
  publisher={American Accounting Association}
}
@article{asquith2005information,
  title={Information content of equity analyst reports},
  author={Asquith, Paul and Mikhail, Michael B and Au, Andrea S},
  journal={Journal of financial economics},
  volume={75},
  number={2},
  pages={245--282},
  year={2005},
  publisher={Elsevier}
}

@misc{BloombergReutersDataset2015,
  author = {Philippe Remy, Xiao Ding},
  title = {Financial News Dataset from Bloomberg and Reuters},
  year = {2015},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/philipperemy/financial-news-dataset}},
}
@inproceedings{ding2014using,
  title={Using structured events to predict stock price movement: An empirical investigation},
  author={Ding, Xiao and Zhang, Yue and Liu, Ting and Duan, Junwen},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1415--1425},
  year={2014}
}

@article{bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{contrastiveloss,
  title={Supervised Contrastive Learning for Pre-trained Language Model Fine-tuning},
  author={Beliz Gunel and Jingfei Du and Alexis Conneau and Ves Stoyanov},
  journal={ArXiv},
  year={2021},
  volume={abs/2011.01403}
}

@incollection{pytorch,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@article{transformers,
  title={Attention is All you Need},
  author={Ashish Vaswani and Noam M. Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  journal={ArXiv},
  year={2017},
  volume={abs/1706.03762}
}

@inproceedings{huggingface,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}

@article{finphrasebank,
author = {Malo, Pekka and Sinha, Ankur and Takala, Pyry and Korhonen, Pekka and Wallenius, Jyrki},
year = {2014},
month = {04},
pages = {},
title = {Good Debt or Bad Debt: Detecting Semantic Orientations in Economic Texts},
journal = {Journal of the American Society for Information Science and Technology},
doi = {10.1002/asi.23062}
}

@article{roberta,
  title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},
  author={Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},
  journal={ArXiv},
  year={2019},
  volume={abs/1907.11692}
}

@article{bart,
  title={BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension},
  author={M. Lewis and Yinhan Liu and Naman Goyal and Marjan Ghazvininejad and Abdelrahman Mohamed and Omer Levy and Veselin Stoyanov and Luke Zettlemoyer},
  journal={ArXiv},
  year={2020},
  volume={abs/1910.13461}
}

@article{transformer,
  title={Attention is All you Need},
  author={Ashish Vaswani and Noam M. Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  journal={ArXiv},
  year={2017},
  volume={abs/1706.03762}
}
@inproceedings{gpt2,
  title={Language Models are Unsupervised Multitask Learners},
  author={Alec Radford and Jeff Wu and R. Child and David Luan and Dario Amodei and Ilya Sutskever},
  year={2019}
}

@inproceedings{word2vec,
  title={Efficient Estimation of Word Representations in Vector Space},
  author={Tomas Mikolov and Kai Chen and G. Corrado and J. Dean},
  booktitle={ICLR},
  year={2013}
}

@inproceedings{elmo,
    title = "Deep Contextualized Word Representations",
    author = "Peters, Matthew E.  and
      Neumann, Mark  and
      Iyyer, Mohit  and
      Gardner, Matt  and
      Clark, Christopher  and
      Lee, Kenton  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-1202",
    doi = "10.18653/v1/N18-1202",
    pages = "2227--2237",
}

@article{biobert,
    author = {Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo},
    title = "{BioBERT: a pre-trained biomedical language representation model for biomedical text mining}",
    journal = {Bioinformatics},
    year = {2019},
    month = {09},
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/btz682},
    url = {https://doi.org/10.1093/bioinformatics/btz682},
}

@inproceedings{scibert,
  title={SciBERT: Pretrained Language Model for Scientific Text},
  author={Iz Beltagy and Kyle Lo and Arman Cohan},
  year={2019},
  booktitle={EMNLP},
  Eprint={arXiv:1903.10676}
}

@inproceedings{clinicalbert,
    title = "Publicly Available Clinical {BERT} Embeddings",
    author = "Alsentzer, Emily  and
      Murphy, John  and
      Boag, William  and
      Weng, Wei-Hung  and
      Jin, Di  and
      Naumann, Tristan  and
      McDermott, Matthew",
    booktitle = "Proceedings of the 2nd Clinical Natural Language Processing Workshop",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-1909",
    doi = "10.18653/v1/W19-1909",
    pages = "72--78"
}

@inproceedings{neuralmask,
  author    = {Minki Kang and
               Moonsu Han and
               Sung Ju Hwang},
  title     = {Neural Mask Generator: Learning to Generate Adaptive Word Maskings
               for Language Model Adaptation},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural
               Language Processing, {EMNLP} 2020, Online, November 16-20, 2020},
  pages     = {6102--6120},
  year      = {2020},
}

@article{domain1,
  title={How to Fine-Tune BERT for Text Classification?},
  author={Chi Sun and Xipeng Qiu and Yige Xu and X. Huang},
  journal={ArXiv},
  year={2019},
  volume={abs/1905.05583}
}
@inproceedings{domain2,
    title = "Don{'}t Stop Pretraining: Adapt Language Models to Domains and Tasks",
    author = "Gururangan, Suchin  and
      Marasovi{\'c}, Ana  and
      Swayamdipta, Swabha  and
      Lo, Kyle  and
      Beltagy, Iz  and
      Downey, Doug  and
      Smith, Noah A.",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.740",
    doi = "10.18653/v1/2020.acl-main.740",
    pages = "8342--8360",
}



@inproceedings{masking2,
  title={Span Selection Pre-training for Question Answering},
  author={Michael R. Glass and A. Gliozzo and Rishav Chakravarti and Anthony Ferritto and Lin Pan and G P Shrivatsa Bhargav and Dinesh Garg and Avirup Sil},
  booktitle={ACL},
  year={2020}
}

@article{ernie,
  title={ERNIE: Enhanced Representation through Knowledge Integration},
  author={Yu Sun and Shuohuan Wang and Yukun Li and Shikun Feng and Xuyi Chen and Han Zhang and Xin Tian and Danxiang Zhu and Hao Tian and Hua Wu},
  journal={ArXiv},
  year={2019},
  volume={abs/1904.09223}
}

@inproceedings{glue,
  title={GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},
  author={Alex Wang and Amanpreet Singh and Julian Michael and Felix Hill and Omer Levy and Samuel R. Bowman},
  booktitle={BlackboxNLP@EMNLP},
  year={2018}
}

@InProceedings{bookcorpus,
    title = {Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books},
    author = {Zhu, Yukun and Kiros, Ryan and Zemel, Rich and Salakhutdinov, Ruslan and Urtasun, Raquel and Torralba, Antonio and Fidler, Sanja},
    booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
    month = {December},
    year = {2015}
}


@article{yang2018financial_senti,
  title={Financial aspect-based sentiment analysis using deep representations},
  author={Yang, Steve and Rosenfeld, Jason and Makutonin, Jacques},
  journal={arXiv preprint arXiv:1808.07931},
  year={2018}
}

@inproceedings{piao2018financial_senti,
  title={Financial aspect and sentiment predictions with deep neural networks: an ensemble approach},
  author={Piao, Guangyuan and Breslin, John G},
  booktitle={Companion Proceedings of the The Web Conference 2018},
  pages={1973--1977},
  year={2018}
}


@misc{investopedia_dict,
  title={Financial Term Dictionary from Investopedia},
  author={Investopedia},
  howpublished={\url{https://www.investopedia.com/financial-term-dictionary-4769738}}
}

@misc{financial_dict_1,
  title={Personal Finance and Financial Literacy},
  author={Vocabulary.com},
  howpublished={\url{https://www.vocabulary.com/lists/1504643}}
}

@misc{financial_dict_2,
  title={BUSINESS, FINANCE AND ECONOMICS VOCABULARY WORD LIST},
  author={MyVocabulary.com},
  howpublished={\url{https://myvocabulary.com/word-list/business-finance-and-economics-vocabulary/}}
}



@misc{financial_dict_3,
  title={Financial Word Dictionary},
  author={TheStreet},
  howpublished={\url{https://www.thestreet.com/topic/46001/financial-glossary.html}}
}

@misc{financial_dict_4,
  title={FINANCE VOCABULARY WORD LIST},
  author={MyVocabulary.com},
  howpublished={\url{https://myvocabulary.com/word-list/finance-vocabulary/}}
}

@inproceedings{sawhney2020voltage,
  title={VolTAGE: volatility forecasting via text-audio fusion with graph convolution networks for earnings calls},
  author={Sawhney, Ramit and Khanna, Piyush and Aggarwal, Arshiya and Jain, Taru and Mathur, Puneet and Shah, Rajiv},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={8001--8013},
  year={2020}
}

@article{francis2019transfer,
  title={Transfer learning for named entity recognition in financial and biomedical documents},
  author={Francis, Sumam and Van Landeghem, Jordy and Moens, Marie-Francine},
  journal={Information},
  volume={10},
  number={8},
  pages={248},
  year={2019},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@article{spanbert,
  author    = {Mandar Joshi and
               Danqi Chen and
               Yinhan Liu and
               Daniel S. Weld and
               Luke Zettlemoyer and
               Omer Levy},
  title     = {SpanBERT: Improving Pre-training by Representing and Predicting Spans},
  journal   = {CoRR},
  volume    = {abs/1907.10529},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.10529},
  eprinttype = {arXiv},
  eprint    = {1907.10529},
  timestamp = {Thu, 01 Aug 2019 08:59:33 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1907-10529.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{chava2022measuring,
  title={Measuring Firm-Level Inflation Exposure: A Deep Learning Approach},
  author={Chava, Sudheer and Du, Wendi and Shah, Agam and Zeng, Linghang},
  journal={Available at SSRN 4228332},
  year={2022}
}

 @misc{ wiki,
   author = "{Wikipedia contributors}",
   title = "Wikipedia, The Free Encyclopedia",
   year = "2004",
   url = "https://en.wikipedia.org",
   
 }
 

@misc{gpt3,
  doi = {10.48550/ARXIV.2005.14165},
  
  url = {https://arxiv.org/abs/2005.14165},
  
  author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Language Models are Few-Shot Learners},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{t5,
  doi = {10.48550/ARXIV.1910.10683},
  
  url = {https://arxiv.org/abs/1910.10683},
  
  author = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J.},
  
  keywords = {Machine Learning (cs.LG), Computation and Language (cs.CL), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{xlnet,
  author    = {Zhilin Yang and
               Zihang Dai and
               Yiming Yang and
               Jaime G. Carbonell and
               Ruslan Salakhutdinov and
               Quoc V. Le},
  title     = {XLNet: Generalized Autoregressive Pretraining for Language Understanding},
  journal   = {CoRR},
  volume    = {abs/1906.08237},
  year      = {2019},
  url       = {http://arxiv.org/abs/1906.08237},
  eprinttype = {arXiv},
  eprint    = {1906.08237},
  timestamp = {Mon, 24 Jun 2019 17:28:45 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1906-08237.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Numeracy_for_language,
  author    = {Georgios P. Spithourakis and
               Sebastian Riedel},
  title     = {Numeracy for Language Models: Evaluating and Improving their Ability
               to Predict Numbers},
  journal   = {CoRR},
  volume    = {abs/1805.08154},
  year      = {2018},
  url       = {http://arxiv.org/abs/1805.08154},
  eprinttype = {arXiv},
  eprint    = {1805.08154},
  timestamp = {Mon, 13 Aug 2018 16:48:51 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1805-08154.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
}

@inproceedings{
probing_representations_number_vision_language,
title={Probing Representations of Numbers in Vision and Language Models},
author={Ivana Kajic and Aida Nematzadeh},
booktitle={SVRHM 2022 Workshop @ NeurIPS },
year={2022},
url={https://openreview.net/forum?id=01hQQ16Lc9M}
}

@inproceedings{representing_numbers_in_nlp,
    title = "Representing Numbers in {NLP}: a Survey and a Vision",
    author = "Thawani, Avijit  and
      Pujara, Jay  and
      Ilievski, Filip  and
      Szekely, Pedro",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.53",
    doi = "10.18653/v1/2021.naacl-main.53",
    pages = "644--656",
    abstract = "NLP systems rarely give special consideration to numbers found in text. This starkly contrasts with the consensus in neuroscience that, in the brain, numbers are represented differently from words. We arrange recent NLP work on numeracy into a comprehensive taxonomy of tasks and methods. We break down the subjective notion of numeracy into 7 subtasks, arranged along two dimensions: granularity (exact vs approximate) and units (abstract vs grounded). We analyze the myriad representational choices made by over a dozen previously published number encoders and decoders. We synthesize best practices for representing numbers in text and articulate a vision for holistic numeracy in NLP, comprised of design trade-offs and a unified evaluation.",
}

@article{do_nlp_models,
  author    = {Eric Wallace and
               Yizhong Wang and
               Sujian Li and
               Sameer Singh and
               Matt Gardner},
  title     = {Do {NLP} Models Know Numbers? Probing Numeracy in Embeddings},
  journal   = {CoRR},
  volume    = {abs/1909.07940},
  year      = {2019},
  url       = {http://arxiv.org/abs/1909.07940},
  eprinttype = {arXiv},
  eprint    = {1909.07940},
  timestamp = {Tue, 24 Sep 2019 11:33:51 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1909-07940.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@Inbook{manhattan_distance,
author="Craw, Susan",
editor="Sammut, Claude
and Webb, Geoffrey I.",
title="Manhattan Distance",
bookTitle="Encyclopedia of Machine Learning and Data Mining",
year="2017",
publisher="Springer US",
address="Boston, MA",
pages="790--791",
isbn="978-1-4899-7687-1",
doi="10.1007/978-1-4899-7687-1_511",
url="https://doi.org/10.1007/978-1-4899-7687-1_511"
}

@article{similarity_measures,
AUTHOR = {Wang, Jiapeng and Dong, Yihong},
TITLE = {Measurement of Text Similarity: A Survey},
JOURNAL = {Information},
VOLUME = {11},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {421},
URL = {https://www.mdpi.com/2078-2489/11/9/421},
ISSN = {2078-2489},
ABSTRACT = {Text similarity measurement is the basis of natural language processing tasks, which play an important role in information retrieval, automatic question answering, machine translation, dialogue systems, and document matching. This paper systematically combs the research status of similarity measurement, analyzes the advantages and disadvantages of current methods, develops a more comprehensive classification description system of text similarity measurement algorithms, and summarizes the future development direction. With the aim of providing reference for related research and application, the text similarity measurement method is described by two aspects: text distance and text representation. The text distance can be divided into length distance, distribution distance, and semantic distance; text representation is divided into string-based, corpus-based, single-semantic text, multi-semantic text, and graph-structure-based representation. Finally, the development of text similarity is also summarized in the discussion section.},
DOI = {10.3390/info11090421}
}

@article{popular_models,
  author    = {Bonan Min and
               Hayley Ross and
               Elior Sulem and
               Amir Pouran Ben Veyseh and
               Thien Huu Nguyen and
               Oscar Sainz and
               Eneko Agirre and
               Ilana Heintz and
               Dan Roth},
  title     = {Recent Advances in Natural Language Processing via Large Pre-Trained
               Language Models: {A} Survey},
  journal   = {CoRR},
  volume    = {abs/2111.01243},
  year      = {2021},
  url       = {https://arxiv.org/abs/2111.01243},
  eprinttype = {arXiv},
  eprint    = {2111.01243},
  timestamp = {Fri, 05 Nov 2021 15:25:54 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2111-01243.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

﻿@Article{MOYER1967,
author={Moyer, Robert S.
and Landauer, Thomas K.},
title={Time required for Judgements of Numerical Inequality},
journal={Nature},
year={1967},
month={Sep},
day={01},
volume={215},
number={5109},
pages={1519-1520},
abstract={AN educated adult can tell which of two digits is the larger with virtually no uncertainty. By what process is this accomplished ? On the one hand, it is conceivable that such judgements are made in the same way as judgements of stimuli varying along physical continua. On the other hand, numerical judgements may be made at a different, less perceptual and more cognitive, level. For instance, the task may be one of memory access, each possible pair of numerals being stored with a corresponding inequality sign ; or perhaps some sort of digital computation is performed, such as counting the space between the two numerical values.},
issn={1476-4687},
doi={10.1038/2151519a0},
url={https://doi.org/10.1038/2151519a0}
}

@article{Ramsay1969SomeSC,
  title={Some statistical considerations in multidimensional scaling},
  author={James O. Ramsay},
  journal={Psychometrika},
  year={1969},
  volume={34},
  pages={167-182}
}


%% Vijay's cites, do not add stuff below this line

@article{ansariNeuralCorrelatesSymbolic2005,
  title = {Neural Correlates of Symbolic Number Processing in Children and Adults},
  author = {Ansari, Daniel and Garcia, Nicolas and Lucas, Elizabeth and Hamon, Kathleen and Dhital, Bibek},
  year = {2005},
  journal = {Neuroreport},
  volume = {16},
  number = {16},
  pages = {1769--1773},
  publisher = {{LWW}},
  isbn = {0959-4965}
}

@article{bhatiaAssociativeJudgmentVector2017,
  title = {Associative Judgment and Vector Space Semantics},
  author = {Bhatia, Sudeep},
  year = {2017},
  journal = {Psychological Review},
  volume = {124},
  pages = {1--20},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1471},
  doi = {10.1037/rev0000047},
  abstract = {I study associative processing in high-level judgment using vector space semantic models. I find that semantic relatedness, as quantified by these models, is able to provide a good measure of the associations involved in judgment, and, in turn, predict responses in a large number of existing and novel judgment tasks. My results shed light on the representations underlying judgment, and highlight the close relationship between these representations and those at play in language and in the assessment of word meaning. In doing so, they show how one of the best-known and most studied theories in decision making research can be formalized to make quantitative a priori predictions, and how this theory can be rigorously tested on a wide range of natural language judgment problems. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Associative Processes,Decision Making,Judgment,Semantics},
  file = {/home/vijaymarupudi/techno/linux/zotero/storage/7LG6JTG4/2016-60724-001.html}
}

@article{bhatiaTransformerNetworksHuman2022,
  title = {Transformer Networks of Human Conceptual Knowledge},
  author = {Bhatia, Sudeep and Richie, Russell},
  year = {2022},
  journal = {Psychological Review},
  pages = {No Pagination Specified-No Pagination Specified},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1471},
  doi = {10.1037/rev0000319},
  abstract = {We present a computational model capable of simulating aspects of human knowledge for thousands of real-world concepts. Our approach involves a pretrained transformer network that is further fine-tuned on large data sets of participant-generated feature norms. We show that such a model can successfully extrapolate from its training data, and predict human knowledge for new concepts and features. We apply our model to stimuli from 25 previous experiments in semantic cognition research and show that it reproduces many findings on semantic verification, concept typicality, feature distribution, and semantic similarity. We also compare our model against several variants, and by doing so, establish the model properties that are necessary for good prediction. The success of our approach shows how a combination of language data and (laboratory-based) psychological data can be used to build models with rich world knowledge. Such models can be used in the service of new psychological applications, such as the modeling of naturalistic semantic verification and knowledge retrieval, as well as the modeling of real-world categorization, decision-making, and reasoning. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  keywords = {Classification (Cognitive Process),Computational Modeling,Concepts,Connectionism,Decision Making,Human Information Storage,Judgment,Natural Language Processing,Prediction,Semantic Networks,Semantics,Simulation,Training},
  file = {/home/vijaymarupudi/techno/linux/zotero/storage/KXT9REJB/Bhatia and Richie - 2022 - Transformer networks of human conceptual knowledge.pdf;/home/vijaymarupudi/techno/linux/zotero/storage/U9S764B7/2023-13379-001.html}
}

@article{billockHonorFechnerObey2011,
  title = {To Honor {{Fechner}} and Obey {{Stevens}}: {{Relationships}} between Psychophysical and Neural Nonlinearities},
  shorttitle = {To Honor {{Fechner}} and Obey {{Stevens}}},
  author = {Billock, Vincent A. and Tsou, Brian H.},
  year = {2011},
  journal = {Psychological Bulletin},
  volume = {137},
  pages = {1--18},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1455},
  doi = {10.1037/a0021394},
  abstract = {G. T. Fechner (1860/1966) famously described two kinds of psychophysics: Outer psychophysics captures the black box relationship between sensory inputs and perceptual magnitudes, whereas inner psychophysics contains the neural transformations that Fechner's outer psychophysics elided. The relationship between the two has never been clear. Moreover, psychophysical power laws are found in almost every sensory system, yet the vast majority of neurons show sigmoid nonlinearities. Here, we selectively review the literatures on psychophysical and physiological nonlinearities and show how they can be placed within a framework for understanding the relationship between inner and outer psychophysics: a neural organization with a logical structure commensurate to outer psychophysical theory. In theoretical treatments of Stevens's law, the power law is a consequence of combining a Weber's law scaling of inputs with a Weber's law\textendash like scaling of sensation magnitudes, yielding an exponent that is the ratio of the Weber constants. A neural derivation using physiological sigmoid nonlinearities should be commensurate to this internal logic. There is a class of models in which two nonlinear neural mechanisms (e.g., a sensory channel and the cortical numerosity mechanism tapped by magnitude estimation) are coupled through feedback, yielding power law behavior as an emergent property of the system, with an exponent that is a ratio of neural coupling strengths. Rather than a discrepancy between psychophysics and physiology, these models suggest complementarity between inner and outer psychophysics, because the Weber constants required for outer psychophysics modeling can be derived from the sigmoid nonlinearities of inner psychophysics. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {History of Psychology,Nonlinear Regression,Psychophysics},
  file = {/home/vijaymarupudi/techno/linux/zotero/storage/VWRY6JKZ/2011-00025-001.html}
}

@article{cantlonMathMonkeysDeveloping2012,
  title = {Math, Monkeys, and the Developing Brain},
  author = {Cantlon, Jessica F.},
  year = {2012},
  month = jun,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {109},
  number = {supplement\_1},
  pages = {10725--10732},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.1201893109},
  abstract = {Thirty thousand years ago, humans kept track of numerical quantities by carving slashes on fragments of bone. It took approximately 25,000 y for the first iconic written numerals to emerge among human cultures (e.g., Sumerian cuneiform). Now, children acquire the meanings of verbal counting words, Arabic numerals, written number words, and the procedures of basic arithmetic operations, such as addition and subtraction, in just 6 y (between ages 2 and 8). What cognitive abilities enabled our ancestors to record tallies in the first place? Additionally, what cognitive abilities allow children to rapidly acquire the formal mathematics knowledge that took our ancestors many millennia to invent? Current research aims to discover the origins and organization of numerical information in humans using clues from child development, the organization of the human brain, and animal cognition.},
  file = {/home/vijaymarupudi/techno/linux/zotero/storage/3GLL8RG2/Cantlon - 2012 - Math, monkeys, and the developing brain.pdf}
}

@article{cohenkadoshAreNumbersSpecial2008,
  title = {Are Numbers Special? {{An}} Overview of Chronometric, Neuroimaging, Developmental and Comparative Studies of Magnitude Representation},
  shorttitle = {Are Numbers Special?},
  author = {Cohen Kadosh, Roi and Lammertyn, Jan and Izard, Veronique},
  year = {2008},
  month = feb,
  journal = {Progress in Neurobiology},
  volume = {84},
  number = {2},
  pages = {132--147},
  issn = {0301-0082},
  doi = {10.1016/j.pneurobio.2007.11.001},
  abstract = {There is a current debate whether the human brain possesses a shared representation for various types of magnitude such as numerical quantities, physical size, or loudness. Here, we critically review evidence from chronometric, neuroimaging, developmental and comparative fields, and supplement it with a meta-analysis of the neuroimaging data. Together, based on such an integrative overview, we discuss limitations inherent in each approach, and the possibility whether shared, or distinct magnitude representation, or both representations exist.},
  langid = {english},
  keywords = {Animal cognition,Development,Human cognition,Magnitude,Neural specialization,Neuroimaging,Numerical processing,Parietal lobe,Representation},
  file = {/home/vijaymarupudi/techno/linux/zotero/storage/7FIZBCYU/Cohen Kadosh et al. - 2008 - Are numbers special An overview of chronometric, .pdf;/home/vijaymarupudi/techno/linux/zotero/storage/L7U5ETV9/S0301008207002110.html}
}

@article{dehaeneCrosslinguisticRegularitiesFrequency1992,
  title = {Cross-Linguistic Regularities in the Frequency of Number Words},
  author = {Dehaene, Stanislas and Mehler, Jacques},
  year = {1992},
  journal = {Cognition},
  volume = {43},
  number = {1},
  pages = {1--29},
  publisher = {{Elsevier}},
  doi = {10.1016/0010-0277(92)90030-l},
  isbn = {0010-0277}
}

@article{fechnerElementsPsychophysics1860,
  title = {Elements of Psychophysics},
  author = {Fechner, Gustav Theodor},
  year = {1860},
  volume = {1},
  publisher = {{Appleton-Century-Crofts}},
  doi = {10.1037/11304-026}
}

@article{halberdaIndividualDifferencesNonverbal2008,
  ids = {halberdaIndividualDifferencesNonverbal2008a},
  title = {Individual Differences in Non-Verbal Number Acuity Correlate with Maths Achievement},
  author = {Halberda, Justin and Mazzocco, Mich{\`e}le M. M. and Feigenson, Lisa},
  year = {2008},
  month = oct,
  journal = {Nature},
  volume = {455},
  number = {7213},
  pages = {665--668},
  publisher = {{Nature Publishing Group}},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/nature07246},
  langid = {english},
  keywords = {Achievement,Adolescent,Biological Evolution,Child,Child; Preschool,Cognition,Education,Female,Humanities and Social Sciences,Humans,Individuality,Linear Models,Longitudinal Studies,Male,Mathematics,multidisciplinary,Schools,Science},
  file = {/home/vijaymarupudi/techno/linux/zotero/storage/URFV5ZGF/Halberda et al. - 2008 - Individual differences in non-verbal number acuity.pdf}
}

@article{lakeWordMeaningMinds2021,
  ids = {lakeWordMeaningMinds2021a},
  title = {Word Meaning in Minds and Machines.},
  author = {Lake, Brenden M. and Murphy, Gregory L.},
  year = {2021},
  journal = {Psychological review},
  publisher = {{American Psychological Association}},
  address = {{US}},
  doi = {10.1037/rev0000297},
  isbn = {1939-1471},
  keywords = {*Concepts,*Mind,*Models,*Natural Language Processing,*Word Meaning,Human Machine Systems,Neural Networks,Psychological Theories,Semantics}
}

@article{lakeWordMeaningMinds2021a,
  title = {Word Meaning in Minds and Machines},
  author = {Lake, Brenden M. and Murphy, Gregory L.},
  year = {2021},
  journal = {Psychological Review},
  pages = {No Pagination Specified-No Pagination Specified},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1471},
  doi = {10.1037/rev0000297},
  abstract = {Machines have achieved a broad and growing set of linguistic competencies, thanks to recent progress in Natural Language Processing (NLP). Psychologists have shown increasing interest in such models, comparing their output to psychological judgments such as similarity, association, priming, and comprehension, raising the question of whether the models could serve as psychological theories. In this article, we compare how humans and machines represent the meaning of words. We argue that contemporary NLP systems are fairly successful models of human word similarity, but they fall short in many other respects. Current models are too strongly linked to the text-based patterns in large corpora, and too weakly linked to the desires, goals, and beliefs that people express through words. Word meanings must also be grounded in perception and action and be capable of flexible combinations in ways that current systems are not. We discuss promising approaches to grounding NLP systems and argue that they will be more successful, with a more human-like, conceptual basis for word meaning. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
  keywords = {Concepts,Human Machine Systems,Mind,Models,Natural Language Processing,Neural Networks,Psychological Theories,Semantics,Word Meaning},
  file = {/home/vijaymarupudi/techno/linux/zotero/storage/R6E2GS6L/Lake and Murphy - 2021 - Word meaning in minds and machines.pdf;/home/vijaymarupudi/techno/linux/zotero/storage/NIHC8X8A/2021-63913-001.html}
}

@article{merkleyUsingEyeTracking2010,
  title = {Using Eye Tracking to Study Numerical Cognition: The Case of the Ratio Effect},
  shorttitle = {Using Eye Tracking to Study Numerical Cognition},
  author = {Merkley, Rebecca and Ansari, Daniel},
  year = {2010},
  month = oct,
  journal = {Experimental Brain Research},
  volume = {206},
  number = {4},
  pages = {455--460},
  issn = {1432-1106},
  doi = {10.1007/s00221-010-2419-8},
  abstract = {In both behavioural and brain-imaging studies, numerical magnitude comparison tasks have been used to glean insights into the processing and representation of numerical magnitude. The present study examined the extent to which eye movement data can be used to investigate the neurocognitive processes underlying numerical magnitude processing. Twenty-two participants performed a numerical comparison task (deciding which of two Arabic numerals represents the larger numerical magnitude) while eye tracking data was recorded. The ratio between numbers (smaller/larger) was manipulated and ranged from 0.11 to 0.89. Consistent with previous reaction time and accuracy studies, the present results demonstrated significant main effects of ratio on the number of fixations, as well as a significant main effect of correct (numerically larger) versus incorrect (numerically smaller) number on the duration of fixations. Furthermore, data from the present investigation also revealed that participants made significantly more saccades between the two numbers for large relative to small ratio trials. Moreover, the ratio effects on eye movements were uncorrelated with the effect of numerical ratio on reaction times, suggesting that eye tracking measures of number comparison may tap into a different level of numerical magnitude processing than reaction time measures do.},
  langid = {english},
  keywords = {Eye tracking,Number processing,Numerical comparison,Numerical magnitude,Ratio effect},
  file = {/home/vijaymarupudi/techno/linux/zotero/storage/ZHB2L3N8/Merkley and Ansari - 2010 - Using eye tracking to study numerical cognition t.pdf}
}

@misc{mikolovEfficientEstimationWord2013,
  title = {Efficient {{Estimation}} of {{Word Representations}} in {{Vector Space}}},
  author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  year = {2013},
  month = sep,
  number = {arXiv:1301.3781},
  eprint = {1301.3781},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1301.3781},
  abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {/home/vijaymarupudi/techno/linux/zotero/storage/RWCYM4X3/Mikolov et al. - 2013 - Efficient Estimation of Word Representations in Ve.pdf;/home/vijaymarupudi/techno/linux/zotero/storage/4B8E6KBX/1301.html}
}

@article{moyerTimeRequiredJudgements1967,
  ids = {moyerTimeRequiredJudgements1967a},
  title = {Time Required for Judgements of Numerical Inequality},
  author = {Moyer, Robert S. and Landauer, Thomas K.},
  year = {1967},
  journal = {Nature},
  volume = {215},
  number = {5109},
  pages = {1519--1520},
  publisher = {{Springer}},
  isbn = {0028-0836},
  keywords = {Humanities and Social Sciences,Judgment,multidisciplinary,Numbers (Numerals),Science,Time},
  file = {/home/vijaymarupudi/techno/linux/zotero/storage/Q4UZLDD2/Moyer and Landauer - 1967 - Time required for Judgements of Numerical Inequali.pdf;/home/vijaymarupudi/techno/linux/zotero/storage/SS9SGCGK/1968-00331-001.html}
}

@article{niederCodingCognitiveMagnitude2003,
  title = {Coding of {{Cognitive Magnitude}}: {{Compressed Scaling}} of {{Numerical Information}} in the {{Primate Prefrontal Cortex}}},
  shorttitle = {Coding of {{Cognitive Magnitude}}},
  author = {Nieder, Andreas and Miller, Earl K.},
  year = {2003},
  month = jan,
  journal = {Neuron},
  volume = {37},
  number = {1},
  pages = {149--157},
  issn = {0896-6273},
  doi = {10.1016/S0896-6273(02)01144-3},
  abstract = {Whether cognitive representations are better conceived as language-based, symbolic representations or perceptually related, analog representations is a subject of debate. If cognitive processes parallel perceptual processes, then fundamental psychophysical laws should hold for each. To test this, we analyzed both behavioral and neuronal representations of numerosity in the prefrontal cortex of rhesus monkeys. The data were best described by a nonlinearly compressed scaling of numerical information, as postulated by the Weber-Fechner law or Stevens' law for psychophysical/sensory magnitudes. This nonlinear compression was observed on the neural level during the acquisition phase of the task and maintained through the memory phase with no further compression. These results suggest that certain cognitive and perceptual/sensory representations share the same fundamental mechanisms and neural coding schemes.},
  langid = {english},
  
}

@article{niederRepresentationNumberBrain2009,
  title = {Representation of {{Number}} in the {{Brain}}},
  author = {Nieder, Andreas and Dehaene, Stanislas},
  year = {2009},
  journal = {Annual Review of Neuroscience},
  volume = {32},
  number = {1},
  pages = {185--208},
  doi = {10.1146/annurev.neuro.051508.135550},
  abstract = {Number symbols have allowed humans to develop superior mathematical skills that are a hallmark of technologically advanced cultures. Findings in animal cognition, developmental psychology, and anthropology indicate that these numerical skills are rooted in nonlinguistic biological primitives. Recent studies in human and nonhuman primates using a broad range of methodologies provide evidence that numerical information is represented and processed by regions of the prefrontal and posterior parietal lobes, with the intraparietal sulcus as a key node for the representation of the semantic aspect of numerical quantity.},
  pmid = {19400715},
  keywords = {human functional imaging,intraparietal sulcus,language,monkey single-cell physiology,numerical competence,prefrontal cortex,symbols},
  annotation = {\_eprint: https://doi.org/10.1146/annurev.neuro.051508.135550}
}

@article{niederRepresentingSomethingOut2016,
  title = {Representing {{Something Out}} of {{Nothing}}: {{The Dawning}} of {{Zero}}},
  shorttitle = {Representing {{Something Out}} of {{Nothing}}},
  author = {Nieder, Andreas},
  year = {2016},
  month = nov,
  journal = {Trends in Cognitive Sciences},
  volume = {20},
  number = {11},
  pages = {830--842},
  issn = {1364-6613},
  doi = {10.1016/j.tics.2016.08.008},
  abstract = {Zero stands for emptiness, for nothing, and yet it is considered to be one of the greatest achievements of humankind. This review first recapitulates the discovery of the number zero in human history, then follows its progression in human development, traces its evolution in the animal kingdom, and finally elucidates how the brain transforms `nothing' into an abstract zero category. It is argued that the emergence of zero passes through four corresponding representations in all of these interrelated realms: first, sensory `nothing'; then categorical `something'; then quantitative empty sets; and finally the number zero. The concept of zero shows how the brain, originally evolved to represent stimuli (`something'), detaches from empirical properties to achieve ultimate abstract thinking.},
  langid = {english},
  keywords = {abstraction,association cortex,mathematics,number},
  file = {/home/vijaymarupudi/techno/linux/zotero/storage/WG9QJL2U/S1364661316301255.html}
}

@article{nuerkDecadeBreaksMental2001,
  title = {Decade Breaks in the Mental Number Line? {{Putting}} the Tens and Units Back in Different Bins},
  author = {Nuerk, Hans-Christoph and Weger, Ulrich and Willmes, Klaus},
  year = {2001},
  journal = {Cognition},
  volume = {82},
  number = {1},
  pages = {B25-B33},
  publisher = {{Elsevier}},
  isbn = {0010-0277}
}

@article{parkmanTemporalAspectsDigit1971,
  title = {Temporal Aspects of Digit and Letter Inequality Judgments},
  author = {Parkman, John M.},
  year = {1971},
  journal = {Journal of Experimental Psychology},
  volume = {91},
  number = {2},
  pages = {191--205},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {0022-1015},
  doi = {10.1037/h0031854},
  abstract = {Studied the time needed for adults to indicate which of 2 digits was larger, which of 2 digits was smaller, and which of 2 letters appeared later in the alphabet. 3 experiments were performed with 96 undergraduates. Latencies in both digit tasks were primarily a linear increasing function of the minimum digit of each pair, with responses for indicating the larger digit approximately 40 msec. Faster than those for the smaller digit. Latencies for the letter task were approximately 200-300 msec. Longer than the rts for digits. The pattern of latencies for individual letter pairs was substantially different from the patterns for corresponding digit pairs, suggesting underlying process differences for the 2 types of material. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Judgment,Language,Numbers (Numerals),Thinking,Time},
  file = {/home/vijaymarupudi/techno/linux/zotero/storage/RP5ASJRJ/1972-08230-001.html}
}

@article{richieSimilarityJudgmentCategories2021,
  ids = {richieSimilarityJudgmentCategories2021a},
  title = {Similarity {{Judgment Within}} and {{Across Categories}}: {{A Comprehensive Model Comparison}}},
  shorttitle = {Similarity {{Judgment Within}} and {{Across Categories}}},
  author = {Richie, Russell and Bhatia, Sudeep},
  year = {2021},
  journal = {Cognitive Science},
  volume = {45},
  number = {8},
  pages = {e13030},
  issn = {1551-6709},
  doi = {10.1111/cogs.13030},
  abstract = {Similarity is one of the most important relations humans perceive, arguably subserving category learning and categorization, generalization and discrimination, judgment and decision making, and other cognitive functions. Researchers have proposed a wide range of representations and metrics that could be at play in similarity judgment, yet have not comprehensively compared the power of these representations and metrics for predicting similarity within and across different semantic categories. We performed such a comparison by pairing nine prominent vector semantic representations with seven established similarity metrics that could operate on these representations, as well as supervised methods for dimensional weighting in the similarity function. This approach yields a factorial model structure with 126 distinct representation-metric pairs, which we tested on a novel dataset of similarity judgments between pairs of cohyponymic words in eight categories. We found that cosine similarity and Pearson correlation were the overall best performing unweighted similarity functions, and that word vectors derived from free association norms often outperformed word vectors derived from text (including those specialized for similarity). Importantly, models that used human similarity judgments to learn category-specific weights on dimensions yielded substantially better predictions than all unweighted approaches across all types of similarity functions and representations, although dimension weights did not generalize well across semantic categories, suggesting strong category context effects in similarity judgment. We discuss implications of these results for cognitive modeling and natural language processing, as well as for theories of the representations and metrics involved in similarity.},
  langid = {english},
  keywords = {Association norms,Computational models,Context,Similarity,Vector semantics},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cogs.13030},
  file = {/home/vijaymarupudi/techno/linux/zotero/storage/XBUYPDSD/Richie and Bhatia - 2021 - Similarity Judgment Within and Across Categories .pdf;/home/vijaymarupudi/techno/linux/zotero/storage/97DBTTAJ/cogs.html}
}


@article{awp_1,
             author = { Collin Burns and
               Saurav Kadavath and
               Akul Arora and
               Steven Basart and
               Eric Tang and
               Dawn Song and
               Jacob Steinhardt},
  title     = {Measuring Mathematical Problem Solving With the {MATH} Dataset},
  journal   = {CoRR},
  volume    = {abs/2103.03874},
  year      = {2021},
  url       = {https://arxiv.org/abs/2103.03874},
  eprinttype = {arXiv},
  eprint    = {2103.03874},
  timestamp = {Mon, 15 Mar 2021 17:30:55 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2103-03874.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@misc{filter,
  doi = {10.35111/WK4F-QT80},
  url = {https://catalog.ldc.upenn.edu/LDC2011T07},
  author = {{Parker,  Robert} and {Graff,  David} and {Kong,  Junbo} and {Chen,  Ke} and {Maeda,  Kazuaki}},
  title = {English Gigaword Fifth Edition},
  publisher = {Linguistic Data Consortium},
  year = {2011}
}
@inproceedings{awp_2,
    title = "{M}ath{QA}: Towards Interpretable Math Word Problem Solving with Operation-Based Formalisms",
    author = "Amini, Aida  and
      Gabriel, Saadia  and
      Lin, Shanchuan  and
      Koncel-Kedziorski, Rik  and
      Choi, Yejin  and
      Hajishirzi, Hannaneh",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1245",
    doi = "10.18653/v1/N19-1245",
    pages = "2357--2367",
    abstract = "We introduce a large-scale dataset of math word problems and an interpretable neural math problem solver by learning to map problems to their operation programs. Due to annotation challenges, current datasets in this domain have been either relatively small in scale or did not offer precise operational annotations over diverse problem types. We introduce a new representation language to model operation programs corresponding to each math problem that aim to improve both the performance and the interpretability of the learned models. Using this representation language, we significantly enhance the AQUA-RAT dataset with fully-specified operational programs. We additionally introduce a neural sequence-to-program model with automatic problem categorization. Our experiments show improvements over competitive baselines in our dataset as well as the AQUA-RAT dataset. The results are still lower than human performance indicating that the dataset poses new challenges for future research. Our dataset is available at https://math-qa.github.io/math-QA/",
}
@inproceedings{approx_measurement,
    title = "Do Language Embeddings capture Scales?",
    author = "Zhang, Xikun  and
      Ramachandran, Deepak  and
      Tenney, Ian  and
      Elazar, Yanai  and
      Roth, Dan",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.439",
    doi = "10.18653/v1/2020.findings-emnlp.439",
    pages = "4889--4896",
    abstract = "Pretrained Language Models (LMs) have been shown to possess significant linguistic, common sense and factual knowledge. One form of knowledge that has not been studied yet in this context is information about the scalar magnitudes of objects. We show that pretrained language models capture a significant amount of this information but are short of the capability required for general common-sense reasoning. We identify contextual information in pre-training and numeracy as two key factors affecting their performance, and show that a simple method of canonicalizing numbers can have a significant effect on the results.",
}
@inproceedings{exact_facts,
    title = "{B}irds have four legs?! {N}umer{S}ense: {P}robing {N}umerical {C}ommonsense {K}nowledge of {P}re-{T}rained {L}anguage {M}odels",
    author = "Lin, Bill Yuchen  and
      Lee, Seyeon  and
      Khanna, Rahul  and
      Ren, Xiang",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.557",
    doi = "10.18653/v1/2020.emnlp-main.557",
    pages = "6862--6868",
    abstract = "Recent works show that pre-trained language models (PTLMs), such as BERT, possess certain commonsense and factual knowledge. They suggest that it is promising to use PTLMs as {``}neural knowledge bases{''} via predicting masked words. Surprisingly, we find that this may not work for numerical commonsense knowledge (e.g., a bird usually has two legs). In this paper, we investigate whether and to what extent we can induce numerical commonsense knowledge from PTLMs as well as the robustness of this process. In this paper, we investigate whether and to what extent we can induce numerical commonsense knowledge from PTLMs as well as the robustness of this process. To study this, we introduce a novel probing task with a diagnostic dataset, NumerSense, containing 13.6k masked-word-prediction probes (10.5k for fine-tuning and 3.1k for testing). Our analysis reveals that: (1) BERT and its stronger variant RoBERTa perform poorly on the diagnostic dataset prior to any fine-tuning; (2) fine-tuning with distant supervision brings some improvement; (3) the best supervised model still performs poorly as compared to human performance (54.06{\%} vs. 96.3{\%} in accuracy).",
}
@article{wallace_2019,
  author    = {Eric Wallace and
               Yizhong Wang and
               Sujian Li and
               Sameer Singh and
               Matt Gardner},
  title     = {Do {NLP} Models Know Numbers? Probing Numeracy in Embeddings},
  journal   = {CoRR},
  volume    = {abs/1909.07940},
  year      = {2019},
  url       = {http://arxiv.org/abs/1909.07940},
  eprinttype = {arXiv},
  eprint    = {1909.07940},
  timestamp = {Tue, 24 Sep 2019 11:33:51 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1909-07940.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{downstream_training,
  author    = {Gail Weiss and
               Yoav Goldberg and
               Eran Yahav},
  title     = {On the Practical Computational Power of Finite Precision RNNs for
               Language Recognition},
  journal   = {CoRR},
  volume    = {abs/1805.04908},
  year      = {2018},
  url       = {http://arxiv.org/abs/1805.04908},
  eprinttype = {arXiv},
  eprint    = {1805.04908},
  timestamp = {Mon, 13 Aug 2018 16:48:39 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1805-04908.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Geva_at_al,
  author    = {Mor Geva and
               Ankit Gupta and
               Jonathan Berant},
  title     = {Injecting Numerical Reasoning Skills into Language Models},
  journal   = {CoRR},
  volume    = {abs/2004.04487},
  year      = {2020},
  url       = {https://arxiv.org/abs/2004.04487},
  eprinttype = {arXiv},
  eprint    = {2004.04487},
  timestamp = {Fri, 27 May 2022 16:07:27 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2004-04487.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}




@online{Symbol_grounding,
  author = {Stevan Harnad},
  title = {Symbol grounding problem
},
  year = 2023,
  url = {http://www.scholarpedia.org/article/Symbol_grounding_problem},
  urldate = {2023-01-01}
}

@article{cite1,
  doi = {10.1126/science.1094492},
  url = {https://doi.org/10.1126/science.1094492},
  year = {2004},
  month = oct,
  publisher = {American Association for the Advancement of Science ({AAAS})},
  volume = {306},
  number = {5695},
  pages = {496--499},
  author = {Peter Gordon},
  title = {Numerical Cognition Without Words: Evidence from Amazonia},
  journal = {Science}
}

@article{cite2,
  doi = {10.1126/science.1102085},
  url = {https://doi.org/10.1126/science.1102085},
  year = {2004},
  month = oct,
  publisher = {American Association for the Advancement of Science ({AAAS})},
  volume = {306},
  number = {5695},
  pages = {499--503},
  author = {Pierre Pica and Cathy Lemer and Ve'ronique Izard and Stanislas Dehaene},
  title = {Exact and Approximate Arithmetic in an Amazonian Indigene Group},
  journal = {Science}
}

@article{cite3,
title = {The language user as an arithmetician},
journal = {Cognition},
volume = {59},
number = {2},
pages = {219-237},
year = {1996},
issn = {0010-0277},
doi = {https://doi.org/10.1016/0010-0277(95)00704-0},
url = {https://www.sciencedirect.com/science/article/pii/0010027795007040},
author = {Thijs Pollmann and Carel Jansen},
abstract = {Dutch, like other languages, has approximative expressions with two numerals, for example: “twee, drie boeken” (lit. two, three books; two or three books). This construction is analysed. It turns out that the choice of number words is not arbitrary. Various kinds of factor are involved, as is shown using language materials from large corpora of Dutch texts. The interval between the two numbers has to be 1, 2, 212 or 5, multiplied by 10n, at least in the decimal number system. It is argued that in daily life this set of so-called “favourite numbers” has a special role. Coins and banknotes, prices of special offers, bidding conventions in auctions are based on, or make use of, this set of numbers. An explanation for this favouritism is offered in the framework of the triple-code model of human number processing proposed by Dehaene. The explanation substantiates Dehaene's claim of the existence of an analogue magnitude code used in estimating and comparing. Human cognition seems to be able to perform simple calculations with quantities (e.g., halving and doubling), independently of any counting or number system.}
}

@book{mds_BorgGroenen2005,
  added-at = {2008-01-07T11:06:22.000+0100},
  author = {Borg, I. and Groenen, P.J.F.},
  biburl = {https://www.bibsonomy.org/bibtex/2b9360235f054e3b2ff0e4b4a0c63b4eb/tmalsburg},
  interhash = {43d65ae9bb296e8b9f145d6b685c94fc},
  intrahash = {b9360235f054e3b2ff0e4b4a0c63b4eb},
  keywords = {dimensionalityreduction mds method statistics},
  publisher = {Springer},
  timestamp = {2008-01-07T11:06:22.000+0100},
  title = {{Modern Multidimensional Scaling: Theory and Applications}},
  year = 2005
}


@book{mds_Ding2018,
  doi = {10.1007/978-3-319-78172-3},
  url = {https://doi.org/10.1007/978-3-319-78172-3},
  year = {2018},
  publisher = {Springer International Publishing},
  author = {Cody S. Ding},
  title = {Fundamentals of Applied Multidimensional Scaling for Educational and Psychological Research}
}

@misc{chinchilla,
      title={Training Compute-Optimal Large Language Models}, 
      author={Jordan Hoffmann and Sebastian Borgeaud and Arthur Mensch and Elena Buchatskaya and Trevor Cai and Eliza Rutherford and Diego de Las Casas and Lisa Anne Hendricks and Johannes Welbl and Aidan Clark and Tom Hennigan and Eric Noland and Katie Millican and George van den Driessche and Bogdan Damoc and Aurelia Guy and Simon Osindero and Karen Simonyan and Erich Elsen and Jack W. Rae and Oriol Vinyals and Laurent Sifre},
      year={2022},
      eprint={2203.15556},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{trx,
  author = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert},
  title = {TRL: Transformer Reinforcement Learning},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/lvwerra/trl}}
}

@misc{sanh2020distilbert,
      title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter}, 
      author={Victor Sanh and Lysandre Debut and Julien Chaumond and Thomas Wolf},
      year={2020},
      eprint={1910.01108},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{EMNLP_raj,
  author = {Shah, Raj Sanjay and Chawla, Kunal and Eidnani, Dheeraj and Shah, Agam and Du, Wendi and Chava, Sudheer and Raman, Natraj and Smiley, Charese and Chen, Jiaao and Yang, Diyi},
  title = {When FLUE Meets FLANG: Benchmarks and Large Pretrained Language Model for Financial Domain},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year = {2022},
  publisher = {Association for Computational Linguistics},
}

@misc{openai2023gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{gatti-etal-2022-vistot,
    title = "{V}is{T}o{T}: Vision-Augmented Table-to-Text Generation",
    author = "Gatti, Prajwal  and
      Mishra, Anand  and
      Gupta, Manish  and
      Das Gupta, Mithun",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.675",
    pages = "9936--9949",
    abstract = "Table-to-text generation has been widely studied in the Natural Language Processing community in the recent years. We give a new perspective to this problem by incorporating signals from both tables as well as associated images to generate relevant text. While tables contain a structured list of facts, images are a rich source of unstructured visual information. For example, in the tourism domain, images can be used to infer knowledge such as the type of landmark (e.g., church), its architecture (e.g., Ancient Roman), and composition (e.g., white marble). Therefore, in this paper, we introduce the novel task of Vision-augmented Table-To-Text Generation (VisToT, defined as follows: given a table and an associated image, produce a descriptive sentence conditioned on the multimodal input. For the task, we present a novel multimodal table-to-text dataset, WikiLandmarks, covering 73,084 unique world landmarks. Further, we also present a competitive architecture, namely, VT3 that generates accurate sentences conditioned on the image and table pairs. Through extensive analyses and experiments, we show that visual cues from images are helpful in (i) inferring missing information from incomplete or sparse tables, and (ii) strengthening the importance of useful information from noisy tables for natural language generation. We make the code and data publicly available.",
}

@misc{warstadt2023papers,
      title={Call for Papers -- The BabyLM Challenge: Sample-efficient pretraining on a developmentally plausible corpus}, 
      author={Alex Warstadt and Leshem Choshen and Aaron Mueller and Adina Williams and Ethan Wilcox and Chengxu Zhuang},
      year={2023},
      eprint={2301.11796},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{yiu2023imitation,
      title={Imitation versus Innovation: What children can do that large language and language-and-vision models cannot (yet)?}, 
      author={Eunice Yiu and Eliza Kosoy and Alison Gopnik},
      year={2023},
      eprint={2305.07666},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{shah2023numeric,
      title={Numeric Magnitude Comparison Effects in Large Language Models}, 
      author={Raj Sanjay Shah and Vijay Marupudi and Reba Koenen and Khushi Bhardwaj and Sashank Varma},
      year={2023},
      eprint={2305.10782},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}


@article{tay2021scale,
  title={Scale efficiently: Insights from pre-training and fine-tuning transformers},
  author={Tay, Yi and Dehghani, Mostafa and Rao, Jinfeng and Fedus, William and Abnar, Samira and Chung, Hyung Won and Narang, Sharan and Yogatama, Dani and Vaswani, Ashish and Metzler, Donald},
  journal={arXiv preprint arXiv:2109.10686},
  year={2021}
}

@article{perez2021much,
  title={How much pretraining data do language models need to learn syntax?},
  author={P{\'e}rez-Mayos, Laura and Ballesteros, Miguel and Wanner, Leo},
  journal={arXiv preprint arXiv:2109.03160},
  year={2021}
}

@article{Dupoux_2018,
	doi = {10.1016/j.cognition.2017.11.008},  
	url = {https://doi.org/10.1016%2Fj.cognition.2017.11.008}, 
	year = 2018,
	month = {apr},
	publisher = {Elsevier {BV}
},
	volume = {173},
	pages = {43--59},
	author = {Emmanuel Dupoux},
	title = {Cognitive science in the era of artificial intelligence: A roadmap for reverse-engineering the infant language-learner},
	journal = {Cognition}
}

@misc{pi2022reasoning,
      title={Reasoning Like Program Executors}, 
      author={Xinyu Pi and Qian Liu and Bei Chen and Morteza Ziyadi and Zeqi Lin and Qiang Fu and Yan Gao and Jian-Guang Lou and Weizhu Chen},
      year={2022},
      eprint={2201.11473},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{zhong2019improving,
  title={Improving question answering by commonsense-based pre-training},
  author={Zhong, Wanjun and Tang, Duyu and Duan, Nan and Zhou, Ming and Wang, Jiahai and Yin, Jian},
  booktitle={Natural Language Processing and Chinese Computing: 8th CCF International Conference, NLPCC 2019, Dunhuang, China, October 9--14, 2019, Proceedings, Part I 8},
  pages={16--28},
  year={2019},
  organization={Springer}
}

@misc{rajapakse2019simpletransformers,
  title={Simple Transformers},
  author={Rajapakse, T. C.},
  year={2019},
  howpublished={\url{https://github.com/ThilinaRajapakse/simpletransformers}},
}

@article{pi2022logigan,
  title={Logigan: Learning logical reasoning via adversarial pre-training},
  author={Pi, Xinyu and Zhong, Wanjun and Gao, Yan and Duan, Nan and Lou, Jian-Guang},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={16290--16304},
  year={2022}
}







@article{doi:10.3102/0034654307313795,
author = {Valerie J. Shute},
title ={Focus on Formative Feedback},
journal = {Review of Educational Research},
volume = {78},
number = {1},
pages = {153-189},
year = {2008},
doi = {10.3102/0034654307313795},

URL = { 
        https://doi.org/10.3102/0034654307313795
    
},
eprint = { 
        https://doi.org/10.3102/0034654307313795
    
}
,
    abstract = { This article reviews the corpus of research on feedback, with a focus on formative feedback—defined as information communicated to the learner that is intended to modify his or her thinking or behavior to improve learning. According to researchers, formative feedback should be nonevaluative, supportive, timely, and specific. Formative feedback is usually presented as information to a learner in response to some action on the learner’s part. It comes in a variety of types (e.g., verification of response accuracy, explanation of the correct answer, hints, worked examples) and can be administered at various times during the learning process (e.g., immediately following an answer, after some time has elapsed). Finally, several variables have been shown to interact with formative feedback’s success at promoting learning (e.g., individual characteristics of the learner and aspects of the task). All of these issues are discussed. This review concludes with guidelines for generating formative feedback. }
}


@misc{wei2022emergent,
      title={Emergent Abilities of Large Language Models}, 
      author={Jason Wei and Yi Tay and Rishi Bommasani and Colin Raffel and Barret Zoph and Sebastian Borgeaud and Dani Yogatama and Maarten Bosma and Denny Zhou and Donald Metzler and Ed H. Chi and Tatsunori Hashimoto and Oriol Vinyals and Percy Liang and Jeff Dean and William Fedus},
      year={2022},
      eprint={2206.07682},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{DBLP:journals/corr/abs-2106-01144,
  author       = {Siyang Liu and
                  Chujie Zheng and
                  Orianna Demasi and
                  Sahand Sabour and
                  Yu Li and
                  Zhou Yu and
                  Yong Jiang and
                  Minlie Huang},
  title        = {Towards Emotional Support Dialog Systems},
  journal      = {CoRR},
  volume       = {abs/2106.01144},
  year         = {2021},
  url          = {https://arxiv.org/abs/2106.01144},
  eprinttype    = {arXiv},
  eprint       = {2106.01144},
  timestamp    = {Tue, 27 Jun 2023 15:48:45 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2106-01144.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

=